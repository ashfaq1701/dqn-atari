{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-05T20:01:39.319150Z",
     "start_time": "2024-04-05T20:01:37.165093Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from src.main import train_dqn\n",
    "from src.visualization import plot_rewards, plot_q, plot_all_rewards"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A.L.E: Arcade Learning Environment (version 0.8.1+53f58b7)\n",
      "[Powered by Stella]\n",
      "2024-04-05 21:01:39.379435: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2 Max\n",
      "2024-04-05 21:01:39.379457: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 32.00 GB\n",
      "2024-04-05 21:01:39.379460: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 10.67 GB\n",
      "2024-04-05 21:01:39.379478: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-04-05 21:01:39.379488: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1, Steps: 623, eps: 1.000, total rewards: 300.0\n",
      "Episode: 2, Steps: 287, eps: 1.000, total rewards: 30.0\n",
      "Episode: 3, Steps: 530, eps: 1.000, total rewards: 155.0\n",
      "Episode: 4, Steps: 412, eps: 1.000, total rewards: 35.0\n",
      "Episode: 5, Steps: 487, eps: 1.000, total rewards: 100.0\n",
      "Episode: 6, Steps: 454, eps: 1.000, total rewards: 120.0\n",
      "Episode: 7, Steps: 918, eps: 1.000, total rewards: 415.0\n",
      "Episode: 8, Steps: 514, eps: 1.000, total rewards: 155.0\n",
      "Episode: 9, Steps: 468, eps: 1.000, total rewards: 95.0\n",
      "Episode: 10, Steps: 288, eps: 1.000, total rewards: 45.0\n",
      "Episode: 11, Steps: 746, eps: 1.000, total rewards: 95.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-05 21:01:41.608450: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 12, Steps: 513, eps: 0.999, total rewards: 180.0\n",
      "Episode: 13, Steps: 483, eps: 0.999, total rewards: 150.0\n",
      "Episode: 14, Steps: 402, eps: 0.999, total rewards: 50.0\n",
      "Episode: 15, Steps: 426, eps: 0.999, total rewards: 120.0\n",
      "Episode: 16, Steps: 526, eps: 0.999, total rewards: 310.0\n",
      "Episode: 17, Steps: 459, eps: 0.999, total rewards: 135.0\n",
      "Episode: 18, Steps: 513, eps: 0.999, total rewards: 135.0\n",
      "Episode: 19, Steps: 527, eps: 0.999, total rewards: 135.0\n",
      "Episode: 20, Steps: 605, eps: 0.999, total rewards: 185.0\n",
      "Episode: 21, Steps: 605, eps: 0.999, total rewards: 60.0\n",
      "Episode: 22, Steps: 459, eps: 0.999, total rewards: 75.0\n",
      "Episode: 23, Steps: 506, eps: 0.999, total rewards: 105.0\n",
      "Episode: 24, Steps: 414, eps: 0.999, total rewards: 55.0\n",
      "Episode: 25, Steps: 389, eps: 0.999, total rewards: 110.0\n",
      "Episode: 26, Steps: 373, eps: 0.999, total rewards: 65.0\n",
      "Episode: 27, Steps: 274, eps: 0.999, total rewards: 20.0\n",
      "Episode: 28, Steps: 457, eps: 0.999, total rewards: 75.0\n",
      "Episode: 29, Steps: 475, eps: 0.999, total rewards: 135.0\n",
      "Episode: 30, Steps: 484, eps: 0.999, total rewards: 120.0\n",
      "Episode: 31, Steps: 512, eps: 0.999, total rewards: 180.0\n",
      "Episode: 32, Steps: 401, eps: 0.998, total rewards: 50.0\n",
      "Episode: 33, Steps: 767, eps: 0.998, total rewards: 230.0\n",
      "Episode: 34, Steps: 725, eps: 0.998, total rewards: 215.0\n",
      "Episode: 35, Steps: 611, eps: 0.998, total rewards: 45.0\n",
      "Episode: 36, Steps: 410, eps: 0.998, total rewards: 75.0\n",
      "Episode: 37, Steps: 795, eps: 0.998, total rewards: 265.0\n",
      "Episode: 38, Steps: 474, eps: 0.998, total rewards: 90.0\n",
      "Episode: 39, Steps: 521, eps: 0.998, total rewards: 180.0\n",
      "Episode: 40, Steps: 571, eps: 0.998, total rewards: 120.0\n",
      "Episode: 41, Steps: 384, eps: 0.998, total rewards: 90.0\n",
      "Episode: 42, Steps: 529, eps: 0.998, total rewards: 135.0\n",
      "Episode: 43, Steps: 503, eps: 0.998, total rewards: 180.0\n",
      "Episode: 44, Steps: 381, eps: 0.998, total rewards: 50.0\n",
      "Episode: 45, Steps: 747, eps: 0.998, total rewards: 315.0\n",
      "Episode: 46, Steps: 277, eps: 0.998, total rewards: 80.0\n",
      "Episode: 47, Steps: 532, eps: 0.998, total rewards: 180.0\n",
      "Episode: 48, Steps: 337, eps: 0.998, total rewards: 50.0\n",
      "Episode: 49, Steps: 565, eps: 0.998, total rewards: 155.0\n",
      "Episode: 50, Steps: 458, eps: 0.998, total rewards: 55.0\n",
      "Episode: 51, Steps: 296, eps: 0.998, total rewards: 105.0\n",
      "Episode: 52, Steps: 302, eps: 0.997, total rewards: 50.0\n",
      "Episode: 53, Steps: 810, eps: 0.997, total rewards: 195.0\n",
      "Episode: 54, Steps: 547, eps: 0.997, total rewards: 155.0\n",
      "Episode: 55, Steps: 888, eps: 0.997, total rewards: 380.0\n",
      "Episode: 56, Steps: 507, eps: 0.997, total rewards: 145.0\n",
      "Episode: 57, Steps: 990, eps: 0.997, total rewards: 275.0\n",
      "Episode: 58, Steps: 376, eps: 0.997, total rewards: 60.0\n",
      "Episode: 59, Steps: 293, eps: 0.997, total rewards: 100.0\n",
      "Episode: 60, Steps: 506, eps: 0.997, total rewards: 105.0\n",
      "Episode: 61, Steps: 1330, eps: 0.997, total rewards: 345.0\n",
      "Episode: 62, Steps: 409, eps: 0.997, total rewards: 90.0\n",
      "Episode: 63, Steps: 456, eps: 0.997, total rewards: 105.0\n",
      "Episode: 64, Steps: 502, eps: 0.997, total rewards: 255.0\n",
      "Episode: 65, Steps: 960, eps: 0.997, total rewards: 260.0\n",
      "Episode: 66, Steps: 613, eps: 0.997, total rewards: 180.0\n",
      "Episode: 67, Steps: 356, eps: 0.997, total rewards: 55.0\n",
      "Episode: 68, Steps: 601, eps: 0.997, total rewards: 150.0\n",
      "Episode: 69, Steps: 444, eps: 0.997, total rewards: 80.0\n",
      "Episode: 70, Steps: 448, eps: 0.997, total rewards: 50.0\n",
      "Episode: 71, Steps: 746, eps: 0.997, total rewards: 485.0\n",
      "Episode: 72, Steps: 414, eps: 0.996, total rewards: 75.0\n",
      "Episode: 73, Steps: 555, eps: 0.996, total rewards: 125.0\n",
      "Episode: 74, Steps: 550, eps: 0.996, total rewards: 210.0\n",
      "Episode: 75, Steps: 285, eps: 0.996, total rewards: 65.0\n",
      "Episode: 76, Steps: 293, eps: 0.996, total rewards: 50.0\n",
      "Episode: 77, Steps: 469, eps: 0.996, total rewards: 120.0\n",
      "Episode: 78, Steps: 277, eps: 0.996, total rewards: 55.0\n",
      "Episode: 79, Steps: 463, eps: 0.996, total rewards: 60.0\n",
      "Episode: 80, Steps: 474, eps: 0.996, total rewards: 105.0\n",
      "Episode: 81, Steps: 391, eps: 0.996, total rewards: 120.0\n",
      "Episode: 82, Steps: 631, eps: 0.996, total rewards: 210.0\n",
      "Episode: 83, Steps: 612, eps: 0.996, total rewards: 140.0\n",
      "Episode: 84, Steps: 387, eps: 0.996, total rewards: 60.0\n",
      "Episode: 85, Steps: 487, eps: 0.996, total rewards: 150.0\n",
      "Episode: 86, Steps: 467, eps: 0.996, total rewards: 200.0\n",
      "Episode: 87, Steps: 502, eps: 0.996, total rewards: 105.0\n",
      "Episode: 88, Steps: 435, eps: 0.996, total rewards: 110.0\n",
      "Episode: 89, Steps: 322, eps: 0.996, total rewards: 60.0\n",
      "Episode: 90, Steps: 748, eps: 0.996, total rewards: 225.0\n",
      "Episode: 91, Steps: 387, eps: 0.996, total rewards: 30.0\n",
      "Episode: 92, Steps: 403, eps: 0.995, total rewards: 60.0\n",
      "Episode: 93, Steps: 313, eps: 0.995, total rewards: 95.0\n",
      "Episode: 94, Steps: 462, eps: 0.995, total rewards: 80.0\n",
      "Episode: 95, Steps: 494, eps: 0.995, total rewards: 120.0\n",
      "Episode: 96, Steps: 740, eps: 0.995, total rewards: 320.0\n",
      "Episode: 97, Steps: 512, eps: 0.995, total rewards: 155.0\n",
      "Episode: 98, Steps: 581, eps: 0.995, total rewards: 155.0\n",
      "Episode: 99, Steps: 389, eps: 0.995, total rewards: 75.0\n",
      "Episode: 100, Steps: 517, eps: 0.995, total rewards: 305.0\n",
      "Episode: 101, Steps: 497, eps: 0.995, total rewards: 135.0\n",
      "Episode: 102, Steps: 566, eps: 0.995, total rewards: 155.0\n",
      "Episode: 103, Steps: 465, eps: 0.995, total rewards: 155.0\n",
      "Episode: 104, Steps: 774, eps: 0.995, total rewards: 515.0\n",
      "Episode: 105, Steps: 501, eps: 0.995, total rewards: 135.0\n",
      "Episode: 106, Steps: 598, eps: 0.995, total rewards: 135.0\n",
      "Episode: 107, Steps: 291, eps: 0.995, total rewards: 45.0\n",
      "Episode: 108, Steps: 595, eps: 0.995, total rewards: 185.0\n",
      "Episode: 109, Steps: 628, eps: 0.995, total rewards: 265.0\n",
      "Episode: 110, Steps: 1017, eps: 0.995, total rewards: 210.0\n",
      "Episode: 111, Steps: 567, eps: 0.995, total rewards: 135.0\n",
      "Episode: 112, Steps: 495, eps: 0.994, total rewards: 255.0\n",
      "Episode: 113, Steps: 477, eps: 0.994, total rewards: 110.0\n",
      "Episode: 114, Steps: 579, eps: 0.994, total rewards: 155.0\n",
      "Episode: 115, Steps: 573, eps: 0.994, total rewards: 120.0\n",
      "Episode: 116, Steps: 579, eps: 0.994, total rewards: 180.0\n",
      "Episode: 117, Steps: 548, eps: 0.994, total rewards: 90.0\n",
      "Episode: 118, Steps: 591, eps: 0.994, total rewards: 210.0\n",
      "Episode: 119, Steps: 464, eps: 0.994, total rewards: 110.0\n",
      "Episode: 120, Steps: 288, eps: 0.994, total rewards: 30.0\n",
      "Episode: 121, Steps: 912, eps: 0.994, total rewards: 485.0\n",
      "Episode: 122, Steps: 426, eps: 0.994, total rewards: 145.0\n",
      "Episode: 123, Steps: 521, eps: 0.994, total rewards: 110.0\n",
      "Episode: 124, Steps: 535, eps: 0.994, total rewards: 105.0\n",
      "Episode: 125, Steps: 612, eps: 0.994, total rewards: 210.0\n",
      "Episode: 126, Steps: 513, eps: 0.994, total rewards: 180.0\n"
     ]
    }
   ],
   "source": [
    "spaceinvaders_rewards, spaceinvaders_max_steps, spaceinvaders_q_values, spaceinvaders_model = train_dqn(\"ALE/SpaceInvaders-v5\", method=\"dqn\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-04-05T20:01:39.320191Z"
    }
   },
   "id": "c46b64e827b718ac",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "plot_rewards(spaceinvaders_rewards, title='SpaceInvaders Rewards Over Episodes')"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "c26e6ff8f46ed62a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "plot_q(spaceinvaders_q_values, title='SpaceInvaders Q Values Over Episodes')"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "15b04636cf37c2e1",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "np.save(\"../data/save/spaceinvaders_rewards_dqn.npy\", np.array(spaceinvaders_rewards))\n",
    "np.save(\"../data/save/spaceinvaders_max_steps_dqn.npy\", np.array(spaceinvaders_max_steps))\n",
    "np.save(\"../data/save/spaceinvaders_q_values_dqn.npy\", np.array(spaceinvaders_q_values))"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "f33d404abe907c6b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "spaceinvaders_model.save(\"../data/saved_models/spaceinvaders_model_dqn.keras\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "3195f5c736fee7d8",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "breakout_rewards, breakout_max_steps, breakout_q_values, breakout_model = train_dqn(\"ALE/Breakout-v5\", method=\"dqn\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "f82aa173445d6d66",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "plot_rewards(breakout_rewards, title='Breakout Rewards Over Episodes')"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "45dcd49a235a6154",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "plot_q(breakout_q_values, title='Breakout Q Values Over Episodes')"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "78854389b773bbb3",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "np.save(\"../data/save/breakout_rewards_dqn.npy\", np.array(breakout_rewards))\n",
    "np.save(\"../data/save/breakout_max_steps_dqn.npy\", np.array(breakout_max_steps))\n",
    "np.save(\"../data/save/breakout_q_values_dqn.npy\", np.array(breakout_q_values))"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "d545abdb6356adc0"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "breakout_model.save(\"../saved_models/breakout_model_dqn.keras\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "b388e7fced5c305b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "seaquest_rewards, seaquest_max_steps, seaquest_q_values, seaquest_model = train_dqn(\"ALE/Seaquest-v5\", method=\"dqn\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "f57d8cef77736078",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "plot_rewards(seaquest_rewards, title='SeaQuest Rewards Over Episodes')"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "8ee1de41cf3df084"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "plot_q(seaquest_rewards, title='SeaQuest Q Values Over Episodes')"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "ce310f77f13f3ef6"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "np.save(\"../data/save/seaquest_rewards_dqn.npy\", np.array(seaquest_rewards))\n",
    "np.save(\"../data/save/seaquest_max_steps_dqn.npy\", np.array(seaquest_max_steps))\n",
    "np.save(\"../data/save/seaquest_q_values_dqn.npy\", np.array(seaquest_q_values))"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "c1945ab336b329ee"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "seaquest_model.save(\"../saved_models/seaquest_model_dqn.keras\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "33e1c69a2a749554"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "pong_rewards, pong_max_steps, pong_q_values, pong_model = train_dqn(\"ALE/Pong-v5\", method=\"dqn\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "86db89be87f0aa1"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "plot_rewards(pong_rewards, title='Pong Rewards Over Episodes')"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "1a581f9736e76fe2"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "plot_q(pong_rewards, title='Pong Q Values Over Episodes')"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "8b31c86b506cc235"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "np.save(\"../data/save/pong_rewards_dqn.npy\", np.array(pong_rewards))\n",
    "np.save(\"../data/save/pong_max_steps_dqn.npy\", np.array(pong_max_steps))\n",
    "np.save(\"../data/save/pong_q_values_dqn.npy\", np.array(pong_q_values))"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "69e0d8f43a6620fd"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "pong_model.save(\"../saved_models/pong_model_dqn.keras\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "241341b8e1a21bdf"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "plot_all_rewards(spaceinvaders_rewards, breakout_rewards, pong_rewards, seaquest_rewards, \"DQN\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "1422dbeb693e441b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "6ea3e38895176ae5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
