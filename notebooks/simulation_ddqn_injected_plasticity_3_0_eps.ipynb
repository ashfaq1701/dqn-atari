{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-18T15:35:46.496558Z",
     "start_time": "2024-04-18T15:35:43.604103Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from src.main import train_dqn\n",
    "from src.visualization import plot_rewards, plot_q, plot_all_rewards"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A.L.E: Arcade Learning Environment (version 0.8.1+53f58b7)\n",
      "[Powered by Stella]\n",
      "2024-04-18 16:35:46.573773: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2 Max\n",
      "2024-04-18 16:35:46.573799: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 32.00 GB\n",
      "2024-04-18 16:35:46.573803: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 10.67 GB\n",
      "2024-04-18 16:35:46.573820: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-04-18 16:35:46.573830: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n",
      "/Users/ashfaq/.local/share/virtualenvs/rl-atari-7yjpj432/lib/python3.11/site-packages/keras/src/layers/convolutional/base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1, Steps: 367, eps: 1.000, total rewards: 20.0\n",
      "Episode: 2, Steps: 388, eps: 1.000, total rewards: 60.0\n",
      "Episode: 3, Steps: 520, eps: 0.999, total rewards: 100.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-18 16:35:47.672110: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 4, Steps: 537, eps: 0.999, total rewards: 60.0\n",
      "Episode: 5, Steps: 476, eps: 0.999, total rewards: 40.0\n",
      "Episode: 6, Steps: 403, eps: 0.999, total rewards: 20.0\n",
      "Episode: 7, Steps: 359, eps: 0.998, total rewards: 20.0\n",
      "Episode: 8, Steps: 616, eps: 0.998, total rewards: 120.0\n",
      "Episode: 9, Steps: 542, eps: 0.998, total rewards: 120.0\n",
      "Episode: 10, Steps: 450, eps: 0.997, total rewards: 60.0\n",
      "Episode: 11, Steps: 476, eps: 0.997, total rewards: 60.0\n",
      "Episode: 12, Steps: 341, eps: 0.997, total rewards: 20.0\n",
      "Episode: 13, Steps: 286, eps: 0.997, total rewards: 0.0\n",
      "Episode: 14, Steps: 588, eps: 0.996, total rewards: 120.0\n",
      "Episode: 15, Steps: 443, eps: 0.996, total rewards: 60.0\n",
      "Episode: 16, Steps: 743, eps: 0.996, total rewards: 160.0\n",
      "Episode: 17, Steps: 397, eps: 0.995, total rewards: 40.0\n",
      "Episode: 18, Steps: 669, eps: 0.995, total rewards: 180.0\n",
      "Episode: 19, Steps: 689, eps: 0.995, total rewards: 80.0\n",
      "Episode: 20, Steps: 639, eps: 0.995, total rewards: 100.0\n",
      "Episode: 21, Steps: 646, eps: 0.994, total rewards: 120.0\n",
      "Episode: 22, Steps: 586, eps: 0.994, total rewards: 100.0\n",
      "Episode: 23, Steps: 340, eps: 0.994, total rewards: 20.0\n",
      "Episode: 24, Steps: 605, eps: 0.993, total rewards: 60.0\n",
      "Episode: 25, Steps: 499, eps: 0.993, total rewards: 60.0\n",
      "Episode: 26, Steps: 963, eps: 0.993, total rewards: 260.0\n",
      "Episode: 27, Steps: 537, eps: 0.993, total rewards: 120.0\n",
      "Episode: 28, Steps: 661, eps: 0.992, total rewards: 140.0\n",
      "Episode: 29, Steps: 843, eps: 0.992, total rewards: 120.0\n",
      "Episode: 30, Steps: 531, eps: 0.992, total rewards: 60.0\n",
      "Episode: 31, Steps: 538, eps: 0.991, total rewards: 60.0\n",
      "Episode: 32, Steps: 1106, eps: 0.991, total rewards: 200.0\n",
      "Episode: 33, Steps: 655, eps: 0.991, total rewards: 140.0\n",
      "Episode: 34, Steps: 431, eps: 0.991, total rewards: 40.0\n",
      "Episode: 35, Steps: 330, eps: 0.990, total rewards: 0.0\n",
      "Episode: 36, Steps: 680, eps: 0.990, total rewards: 140.0\n",
      "Episode: 37, Steps: 739, eps: 0.990, total rewards: 120.0\n",
      "Episode: 38, Steps: 444, eps: 0.989, total rewards: 40.0\n",
      "Episode: 39, Steps: 659, eps: 0.989, total rewards: 140.0\n",
      "Episode: 40, Steps: 575, eps: 0.989, total rewards: 140.0\n",
      "Episode: 41, Steps: 364, eps: 0.989, total rewards: 20.0\n",
      "Episode: 42, Steps: 463, eps: 0.988, total rewards: 60.0\n",
      "Episode: 43, Steps: 947, eps: 0.988, total rewards: 220.0\n",
      "Episode: 44, Steps: 590, eps: 0.988, total rewards: 120.0\n",
      "Episode: 45, Steps: 439, eps: 0.987, total rewards: 20.0\n",
      "Episode: 46, Steps: 386, eps: 0.987, total rewards: 40.0\n",
      "Episode: 47, Steps: 640, eps: 0.987, total rewards: 100.0\n",
      "Episode: 48, Steps: 642, eps: 0.987, total rewards: 180.0\n",
      "Episode: 49, Steps: 353, eps: 0.986, total rewards: 40.0\n",
      "Episode: 50, Steps: 648, eps: 0.986, total rewards: 200.0\n",
      "Episode: 51, Steps: 331, eps: 0.986, total rewards: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ashfaq/.local/share/virtualenvs/rl-atari-7yjpj432/lib/python3.11/site-packages/keras/src/optimizers/base_optimizer.py:576: UserWarning: Gradients do not exist for variables ['hebb_dense1', 'hebb_state_values', 'hebb_raw_advantages'] when minimizing the loss. If using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 52, Steps: 771, eps: 0.985, total rewards: 140.0\n",
      "Episode: 53, Steps: 537, eps: 0.985, total rewards: 60.0\n",
      "Episode: 54, Steps: 427, eps: 0.985, total rewards: 60.0\n",
      "Episode: 55, Steps: 588, eps: 0.985, total rewards: 80.0\n",
      "Episode: 56, Steps: 487, eps: 0.984, total rewards: 80.0\n"
     ]
    }
   ],
   "source": [
    "seaquest_rewards, seaquest_max_steps, seaquest_q_values, seaquest_losses, seaquest_model = train_dqn(\n",
    "    \"ALE/Seaquest-v5\", \n",
    "    method=\"ddqn_injected_plasticity\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-04-18T15:35:46.499652Z"
    }
   },
   "id": "c46b64e827b718ac",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "plot_rewards(seaquest_rewards, title='SeaQuest Rewards Over Episodes')"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "df9d81a80add263f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "plot_q(seaquest_q_values, title='SeaQuest Q Values Over Episodes')"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "9363c284e58742dd"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "np.save(\"../data/save/seaquest_rewards_ddqn_injected_plasticity_0_eps.npy\", np.array(seaquest_rewards))\n",
    "np.save(\"../data/save/seaquest_max_steps_ddqn_injected_plasticity_0_eps.npy\", np.array(seaquest_max_steps))\n",
    "np.save(\"../data/save/seaquest_q_values_ddqn_injected_plasticity_0_eps.npy\", np.array(seaquest_q_values))\n",
    "np.save(\"../data/save/seaquest_losses_ddqn_injected_plasticity_0_eps.npy\", np.array(seaquest_losses))"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "9ac834abdda83c15"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "seaquest_model.save(\"../data/saved_models/seaquest_model_ddqn_injected_plasticity_0_eps.keras\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "2dc338e9aaca9f0d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "6ea3e38895176ae5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
