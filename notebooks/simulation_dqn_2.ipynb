{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-18T15:55:50.565298Z",
     "start_time": "2024-04-18T15:55:48.431997Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from src.main import train_dqn\n",
    "from src.visualization import plot_rewards, plot_q, plot_all_rewards"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A.L.E: Arcade Learning Environment (version 0.8.1+53f58b7)\n",
      "[Powered by Stella]\n",
      "2024-04-18 16:55:50.629915: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2 Max\n",
      "2024-04-18 16:55:50.629940: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 32.00 GB\n",
      "2024-04-18 16:55:50.629943: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 10.67 GB\n",
      "2024-04-18 16:55:50.629960: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-04-18 16:55:50.629970: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1, Steps: 1335, eps: 1.000, total rewards: 352.0\n",
      "Episode: 2, Steps: 980, eps: 1.000, total rewards: 308.0\n",
      "Episode: 3, Steps: 1318, eps: 1.000, total rewards: 352.0\n",
      "Episode: 4, Steps: 1273, eps: 0.999, total rewards: 352.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-18 16:55:52.985791: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 5, Steps: 1311, eps: 0.999, total rewards: 440.0\n",
      "Episode: 6, Steps: 1156, eps: 0.999, total rewards: 396.0\n",
      "Episode: 7, Steps: 1169, eps: 0.999, total rewards: 352.0\n",
      "Episode: 8, Steps: 1470, eps: 0.999, total rewards: 308.0\n",
      "Episode: 9, Steps: 1449, eps: 0.998, total rewards: 264.0\n",
      "Episode: 10, Steps: 1573, eps: 0.998, total rewards: 572.0\n",
      "Episode: 11, Steps: 900, eps: 0.998, total rewards: 220.0\n",
      "Episode: 12, Steps: 1229, eps: 0.998, total rewards: 396.0\n",
      "Episode: 13, Steps: 1454, eps: 0.998, total rewards: 396.0\n",
      "Episode: 14, Steps: 1126, eps: 0.997, total rewards: 132.0\n",
      "Episode: 15, Steps: 1188, eps: 0.997, total rewards: 484.0\n",
      "Episode: 16, Steps: 1494, eps: 0.997, total rewards: 396.0\n",
      "Episode: 17, Steps: 1852, eps: 0.997, total rewards: 616.0\n",
      "Episode: 18, Steps: 996, eps: 0.997, total rewards: 352.0\n",
      "Episode: 19, Steps: 1377, eps: 0.996, total rewards: 264.0\n",
      "Episode: 20, Steps: 1357, eps: 0.996, total rewards: 440.0\n",
      "Episode: 21, Steps: 1104, eps: 0.996, total rewards: 264.0\n",
      "Episode: 22, Steps: 1205, eps: 0.996, total rewards: 264.0\n",
      "Episode: 23, Steps: 1125, eps: 0.996, total rewards: 308.0\n",
      "Episode: 24, Steps: 999, eps: 0.995, total rewards: 132.0\n",
      "Episode: 25, Steps: 1171, eps: 0.995, total rewards: 308.0\n"
     ]
    }
   ],
   "source": [
    "beamrider_rewards, beamrider_max_steps, beamrider_q_values, beamrider_losses, beamrider_model = train_dqn(\"ALE/BeamRider-v5\", method=\"dqn\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-04-18T15:55:50.568502Z"
    }
   },
   "id": "4987271d8425f719"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "plot_rewards(beamrider_rewards, title='Beam Rider Rewards Over Episodes')"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "7002b126ba1499b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "plot_q(beamrider_q_values, title='Beam Rider Q Values Over Episodes')"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "56377475b564c884"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "np.save(\"../data/save/beamrider_rewards_dqn.npy\", np.array(beamrider_rewards))\n",
    "np.save(\"../data/save/beamrider_max_steps_dqn.npy\", np.array(beamrider_max_steps))\n",
    "np.save(\"../data/save/beamrider_q_values_dqn.npy\", np.array(beamrider_q_values))\n",
    "np.save(\"../data/save/beamrider_losses_dqn.npy\", np.array(beamrider_losses))"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "a9e5e9c9e99ae2ed"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "beamrider_model.save(\"../data/saved_models/beamrider_model_dqn.keras\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "id": "5cc174ee10ea06db"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
