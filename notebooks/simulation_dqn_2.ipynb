{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-25T20:42:47.229617Z",
     "start_time": "2024-04-25T20:42:44.192275Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from src.main import train_dqn\n",
    "from src.visualization import plot_rewards, plot_q, plot_all_rewards"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A.L.E: Arcade Learning Environment (version 0.8.1+53f58b7)\n",
      "[Powered by Stella]\n",
      "2024-04-25 21:42:51.132351: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M2 Max\n",
      "2024-04-25 21:42:51.132376: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 32.00 GB\n",
      "2024-04-25 21:42:51.132379: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 10.67 GB\n",
      "2024-04-25 21:42:51.132399: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-04-25 21:42:51.132414: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1, Steps: 321, eps: 1.000, total rewards: 75.0\n",
      "Episode: 2, Steps: 350, eps: 1.000, total rewards: 125.0\n",
      "Episode: 3, Steps: 357, eps: 1.000, total rewards: 175.0\n",
      "Episode: 4, Steps: 297, eps: 1.000, total rewards: 150.0\n",
      "Episode: 5, Steps: 319, eps: 1.000, total rewards: 50.0\n",
      "Episode: 6, Steps: 329, eps: 1.000, total rewards: 125.0\n",
      "Episode: 7, Steps: 437, eps: 0.999, total rewards: 125.0\n",
      "Episode: 8, Steps: 261, eps: 0.999, total rewards: 50.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-25 21:42:52.689676: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 9, Steps: 421, eps: 0.999, total rewards: 475.0\n",
      "Episode: 10, Steps: 374, eps: 0.999, total rewards: 425.0\n",
      "Episode: 11, Steps: 302, eps: 0.999, total rewards: 50.0\n",
      "Episode: 12, Steps: 273, eps: 0.999, total rewards: 100.0\n",
      "Episode: 13, Steps: 333, eps: 0.999, total rewards: 425.0\n",
      "Episode: 14, Steps: 320, eps: 0.999, total rewards: 125.0\n",
      "Episode: 15, Steps: 256, eps: 0.999, total rewards: 50.0\n",
      "Episode: 16, Steps: 294, eps: 0.999, total rewards: 125.0\n",
      "Episode: 17, Steps: 330, eps: 0.998, total rewards: 75.0\n",
      "Episode: 18, Steps: 433, eps: 0.998, total rewards: 250.0\n",
      "Episode: 19, Steps: 291, eps: 0.998, total rewards: 150.0\n",
      "Episode: 20, Steps: 290, eps: 0.998, total rewards: 125.0\n",
      "Episode: 21, Steps: 394, eps: 0.998, total rewards: 150.0\n",
      "Episode: 22, Steps: 388, eps: 0.998, total rewards: 225.0\n",
      "Episode: 23, Steps: 269, eps: 0.998, total rewards: 75.0\n",
      "Episode: 24, Steps: 440, eps: 0.998, total rewards: 475.0\n",
      "Episode: 25, Steps: 320, eps: 0.998, total rewards: 125.0\n",
      "Episode: 26, Steps: 320, eps: 0.998, total rewards: 100.0\n",
      "Episode: 27, Steps: 293, eps: 0.997, total rewards: 25.0\n",
      "Episode: 28, Steps: 415, eps: 0.997, total rewards: 325.0\n",
      "Episode: 29, Steps: 284, eps: 0.997, total rewards: 0.0\n",
      "Episode: 30, Steps: 314, eps: 0.997, total rewards: 75.0\n",
      "Episode: 31, Steps: 305, eps: 0.997, total rewards: 25.0\n",
      "Episode: 32, Steps: 322, eps: 0.997, total rewards: 150.0\n",
      "Episode: 33, Steps: 332, eps: 0.997, total rewards: 50.0\n",
      "Episode: 34, Steps: 425, eps: 0.997, total rewards: 500.0\n",
      "Episode: 35, Steps: 434, eps: 0.997, total rewards: 250.0\n",
      "Episode: 36, Steps: 255, eps: 0.997, total rewards: 50.0\n",
      "Episode: 37, Steps: 299, eps: 0.996, total rewards: 50.0\n",
      "Episode: 38, Steps: 319, eps: 0.996, total rewards: 125.0\n",
      "Episode: 39, Steps: 388, eps: 0.996, total rewards: 125.0\n",
      "Episode: 40, Steps: 314, eps: 0.996, total rewards: 225.0\n",
      "Episode: 41, Steps: 409, eps: 0.996, total rewards: 450.0\n",
      "Episode: 42, Steps: 313, eps: 0.996, total rewards: 150.0\n",
      "Episode: 43, Steps: 325, eps: 0.996, total rewards: 125.0\n",
      "Episode: 44, Steps: 360, eps: 0.996, total rewards: 500.0\n",
      "Episode: 45, Steps: 454, eps: 0.996, total rewards: 175.0\n",
      "Episode: 46, Steps: 384, eps: 0.996, total rewards: 125.0\n",
      "Episode: 47, Steps: 287, eps: 0.995, total rewards: 150.0\n",
      "Episode: 48, Steps: 361, eps: 0.995, total rewards: 150.0\n",
      "Episode: 49, Steps: 371, eps: 0.995, total rewards: 525.0\n",
      "Episode: 50, Steps: 334, eps: 0.995, total rewards: 75.0\n",
      "Episode: 51, Steps: 357, eps: 0.995, total rewards: 150.0\n",
      "Episode: 52, Steps: 314, eps: 0.995, total rewards: 75.0\n",
      "Episode: 53, Steps: 320, eps: 0.995, total rewards: 175.0\n",
      "Episode: 54, Steps: 299, eps: 0.995, total rewards: 50.0\n",
      "Episode: 55, Steps: 308, eps: 0.995, total rewards: 150.0\n",
      "Episode: 56, Steps: 425, eps: 0.995, total rewards: 400.0\n",
      "Episode: 57, Steps: 322, eps: 0.994, total rewards: 100.0\n",
      "Episode: 58, Steps: 300, eps: 0.994, total rewards: 25.0\n",
      "Episode: 59, Steps: 405, eps: 0.994, total rewards: 275.0\n",
      "Episode: 60, Steps: 321, eps: 0.994, total rewards: 150.0\n",
      "Episode: 61, Steps: 321, eps: 0.994, total rewards: 150.0\n",
      "Episode: 62, Steps: 337, eps: 0.994, total rewards: 75.0\n",
      "Episode: 63, Steps: 290, eps: 0.994, total rewards: 0.0\n",
      "Episode: 64, Steps: 296, eps: 0.994, total rewards: 25.0\n",
      "Episode: 65, Steps: 299, eps: 0.994, total rewards: 125.0\n",
      "Episode: 66, Steps: 263, eps: 0.994, total rewards: 50.0\n",
      "Episode: 67, Steps: 321, eps: 0.993, total rewards: 100.0\n",
      "Episode: 68, Steps: 438, eps: 0.993, total rewards: 350.0\n",
      "Episode: 69, Steps: 276, eps: 0.993, total rewards: 75.0\n",
      "Episode: 70, Steps: 327, eps: 0.993, total rewards: 400.0\n",
      "Episode: 71, Steps: 364, eps: 0.993, total rewards: 175.0\n",
      "Episode: 72, Steps: 366, eps: 0.993, total rewards: 450.0\n",
      "Episode: 73, Steps: 350, eps: 0.993, total rewards: 225.0\n",
      "Episode: 74, Steps: 311, eps: 0.993, total rewards: 75.0\n",
      "Episode: 75, Steps: 314, eps: 0.993, total rewards: 50.0\n",
      "Episode: 76, Steps: 354, eps: 0.993, total rewards: 525.0\n",
      "Episode: 77, Steps: 320, eps: 0.992, total rewards: 75.0\n",
      "Episode: 78, Steps: 439, eps: 0.992, total rewards: 575.0\n",
      "Episode: 79, Steps: 292, eps: 0.992, total rewards: 25.0\n",
      "Episode: 80, Steps: 323, eps: 0.992, total rewards: 75.0\n",
      "Episode: 81, Steps: 315, eps: 0.992, total rewards: 75.0\n",
      "Episode: 82, Steps: 300, eps: 0.992, total rewards: 50.0\n",
      "Episode: 83, Steps: 409, eps: 0.992, total rewards: 200.0\n",
      "Episode: 84, Steps: 396, eps: 0.992, total rewards: 500.0\n",
      "Episode: 85, Steps: 294, eps: 0.992, total rewards: 25.0\n",
      "Episode: 86, Steps: 329, eps: 0.992, total rewards: 75.0\n",
      "Episode: 87, Steps: 298, eps: 0.991, total rewards: 50.0\n",
      "Episode: 88, Steps: 450, eps: 0.991, total rewards: 225.0\n",
      "Episode: 89, Steps: 432, eps: 0.991, total rewards: 375.0\n",
      "Episode: 90, Steps: 308, eps: 0.991, total rewards: 50.0\n",
      "Episode: 91, Steps: 303, eps: 0.991, total rewards: 50.0\n",
      "Episode: 92, Steps: 295, eps: 0.991, total rewards: 25.0\n",
      "Episode: 93, Steps: 559, eps: 0.991, total rewards: 1000.0\n",
      "Episode: 94, Steps: 290, eps: 0.991, total rewards: 225.0\n",
      "Episode: 95, Steps: 284, eps: 0.991, total rewards: 0.0\n",
      "Episode: 96, Steps: 325, eps: 0.991, total rewards: 175.0\n",
      "Episode: 97, Steps: 465, eps: 0.990, total rewards: 200.0\n",
      "Episode: 98, Steps: 294, eps: 0.990, total rewards: 25.0\n",
      "Episode: 99, Steps: 435, eps: 0.990, total rewards: 225.0\n",
      "Episode: 100, Steps: 266, eps: 0.990, total rewards: 50.0\n",
      "Episode: 101, Steps: 340, eps: 0.990, total rewards: 100.0\n",
      "Episode: 102, Steps: 331, eps: 0.990, total rewards: 125.0\n",
      "Episode: 103, Steps: 325, eps: 0.990, total rewards: 100.0\n",
      "Episode: 104, Steps: 317, eps: 0.990, total rewards: 75.0\n",
      "Episode: 105, Steps: 437, eps: 0.990, total rewards: 225.0\n",
      "Episode: 106, Steps: 366, eps: 0.990, total rewards: 200.0\n",
      "Episode: 107, Steps: 290, eps: 0.989, total rewards: 125.0\n",
      "Episode: 108, Steps: 273, eps: 0.989, total rewards: 50.0\n",
      "Episode: 109, Steps: 370, eps: 0.989, total rewards: 325.0\n",
      "Episode: 110, Steps: 339, eps: 0.989, total rewards: 125.0\n",
      "Episode: 111, Steps: 365, eps: 0.989, total rewards: 250.0\n",
      "Episode: 112, Steps: 308, eps: 0.989, total rewards: 100.0\n",
      "Episode: 113, Steps: 323, eps: 0.989, total rewards: 150.0\n",
      "Episode: 114, Steps: 488, eps: 0.989, total rewards: 350.0\n",
      "Episode: 115, Steps: 308, eps: 0.989, total rewards: 100.0\n",
      "Episode: 116, Steps: 303, eps: 0.989, total rewards: 50.0\n",
      "Episode: 117, Steps: 301, eps: 0.988, total rewards: 25.0\n",
      "Episode: 118, Steps: 275, eps: 0.988, total rewards: 75.0\n",
      "Episode: 119, Steps: 292, eps: 0.988, total rewards: 25.0\n",
      "Episode: 120, Steps: 314, eps: 0.988, total rewards: 50.0\n",
      "Episode: 121, Steps: 330, eps: 0.988, total rewards: 100.0\n",
      "Episode: 122, Steps: 287, eps: 0.988, total rewards: 0.0\n",
      "Episode: 123, Steps: 465, eps: 0.988, total rewards: 300.0\n",
      "Episode: 124, Steps: 282, eps: 0.988, total rewards: 125.0\n",
      "Episode: 125, Steps: 304, eps: 0.988, total rewards: 50.0\n",
      "Episode: 126, Steps: 316, eps: 0.988, total rewards: 75.0\n",
      "Episode: 127, Steps: 380, eps: 0.987, total rewards: 225.0\n",
      "Episode: 128, Steps: 388, eps: 0.987, total rewards: 300.0\n",
      "Episode: 129, Steps: 309, eps: 0.987, total rewards: 50.0\n",
      "Episode: 130, Steps: 333, eps: 0.987, total rewards: 150.0\n",
      "Episode: 131, Steps: 354, eps: 0.987, total rewards: 200.0\n",
      "Episode: 132, Steps: 309, eps: 0.987, total rewards: 75.0\n",
      "Episode: 133, Steps: 303, eps: 0.987, total rewards: 25.0\n",
      "Episode: 134, Steps: 291, eps: 0.987, total rewards: 0.0\n",
      "Episode: 135, Steps: 278, eps: 0.987, total rewards: 100.0\n",
      "Episode: 136, Steps: 395, eps: 0.987, total rewards: 225.0\n",
      "Episode: 137, Steps: 410, eps: 0.986, total rewards: 225.0\n",
      "Episode: 138, Steps: 286, eps: 0.986, total rewards: 0.0\n",
      "Episode: 139, Steps: 388, eps: 0.986, total rewards: 475.0\n",
      "Episode: 140, Steps: 330, eps: 0.986, total rewards: 100.0\n",
      "Episode: 141, Steps: 332, eps: 0.986, total rewards: 150.0\n",
      "Episode: 142, Steps: 496, eps: 0.986, total rewards: 350.0\n",
      "Episode: 143, Steps: 365, eps: 0.986, total rewards: 175.0\n",
      "Episode: 144, Steps: 358, eps: 0.986, total rewards: 100.0\n",
      "Episode: 145, Steps: 378, eps: 0.986, total rewards: 150.0\n",
      "Episode: 146, Steps: 324, eps: 0.986, total rewards: 100.0\n",
      "Episode: 147, Steps: 358, eps: 0.985, total rewards: 150.0\n",
      "Episode: 148, Steps: 289, eps: 0.985, total rewards: 100.0\n",
      "Episode: 149, Steps: 299, eps: 0.985, total rewards: 100.0\n",
      "Episode: 150, Steps: 411, eps: 0.985, total rewards: 125.0\n",
      "Episode: 151, Steps: 396, eps: 0.985, total rewards: 200.0\n",
      "Episode: 152, Steps: 313, eps: 0.985, total rewards: 50.0\n",
      "Episode: 153, Steps: 304, eps: 0.985, total rewards: 125.0\n",
      "Episode: 154, Steps: 286, eps: 0.985, total rewards: 0.0\n",
      "Episode: 155, Steps: 321, eps: 0.985, total rewards: 125.0\n",
      "Episode: 156, Steps: 295, eps: 0.985, total rewards: 50.0\n",
      "Episode: 157, Steps: 262, eps: 0.984, total rewards: 75.0\n",
      "Episode: 158, Steps: 344, eps: 0.984, total rewards: 150.0\n",
      "Episode: 159, Steps: 369, eps: 0.984, total rewards: 175.0\n",
      "Episode: 160, Steps: 394, eps: 0.984, total rewards: 300.0\n",
      "Episode: 161, Steps: 365, eps: 0.984, total rewards: 425.0\n",
      "Episode: 162, Steps: 361, eps: 0.984, total rewards: 450.0\n",
      "Episode: 163, Steps: 323, eps: 0.984, total rewards: 100.0\n",
      "Episode: 164, Steps: 381, eps: 0.984, total rewards: 150.0\n",
      "Episode: 165, Steps: 333, eps: 0.984, total rewards: 150.0\n",
      "Episode: 166, Steps: 385, eps: 0.984, total rewards: 225.0\n",
      "Episode: 167, Steps: 320, eps: 0.983, total rewards: 100.0\n",
      "Episode: 168, Steps: 296, eps: 0.983, total rewards: 200.0\n",
      "Episode: 169, Steps: 346, eps: 0.983, total rewards: 150.0\n",
      "Episode: 170, Steps: 258, eps: 0.983, total rewards: 25.0\n",
      "Episode: 171, Steps: 359, eps: 0.983, total rewards: 200.0\n",
      "Episode: 172, Steps: 330, eps: 0.983, total rewards: 75.0\n",
      "Episode: 173, Steps: 313, eps: 0.983, total rewards: 100.0\n",
      "Episode: 174, Steps: 360, eps: 0.983, total rewards: 175.0\n",
      "Episode: 175, Steps: 466, eps: 0.983, total rewards: 250.0\n",
      "Episode: 176, Steps: 401, eps: 0.983, total rewards: 225.0\n",
      "Episode: 177, Steps: 279, eps: 0.982, total rewards: 100.0\n",
      "Episode: 178, Steps: 288, eps: 0.982, total rewards: 100.0\n",
      "Episode: 179, Steps: 294, eps: 0.982, total rewards: 25.0\n",
      "Episode: 180, Steps: 295, eps: 0.982, total rewards: 50.0\n",
      "Episode: 181, Steps: 304, eps: 0.982, total rewards: 50.0\n",
      "Episode: 182, Steps: 310, eps: 0.982, total rewards: 75.0\n",
      "Episode: 183, Steps: 250, eps: 0.982, total rewards: 50.0\n",
      "Episode: 184, Steps: 302, eps: 0.982, total rewards: 50.0\n",
      "Episode: 185, Steps: 304, eps: 0.982, total rewards: 50.0\n",
      "Episode: 186, Steps: 310, eps: 0.982, total rewards: 75.0\n",
      "Episode: 187, Steps: 359, eps: 0.981, total rewards: 175.0\n",
      "Episode: 188, Steps: 320, eps: 0.981, total rewards: 100.0\n",
      "Episode: 189, Steps: 312, eps: 0.981, total rewards: 100.0\n",
      "Episode: 190, Steps: 351, eps: 0.981, total rewards: 100.0\n",
      "Episode: 191, Steps: 296, eps: 0.981, total rewards: 25.0\n",
      "Episode: 192, Steps: 326, eps: 0.981, total rewards: 225.0\n",
      "Episode: 193, Steps: 373, eps: 0.981, total rewards: 525.0\n",
      "Episode: 194, Steps: 310, eps: 0.981, total rewards: 50.0\n",
      "Episode: 195, Steps: 380, eps: 0.981, total rewards: 525.0\n",
      "Episode: 196, Steps: 320, eps: 0.981, total rewards: 150.0\n",
      "Episode: 197, Steps: 625, eps: 0.980, total rewards: 675.0\n",
      "Episode: 198, Steps: 297, eps: 0.980, total rewards: 50.0\n",
      "Episode: 199, Steps: 297, eps: 0.980, total rewards: 100.0\n",
      "Episode: 200, Steps: 463, eps: 0.980, total rewards: 625.0\n",
      "Episode: 201, Steps: 286, eps: 0.980, total rewards: 0.0\n",
      "Episode: 202, Steps: 306, eps: 0.980, total rewards: 50.0\n",
      "Episode: 203, Steps: 309, eps: 0.980, total rewards: 50.0\n",
      "Episode: 204, Steps: 353, eps: 0.980, total rewards: 200.0\n",
      "Episode: 205, Steps: 389, eps: 0.980, total rewards: 275.0\n",
      "Episode: 206, Steps: 388, eps: 0.980, total rewards: 200.0\n",
      "Episode: 207, Steps: 326, eps: 0.979, total rewards: 125.0\n",
      "Episode: 208, Steps: 295, eps: 0.979, total rewards: 25.0\n",
      "Episode: 209, Steps: 296, eps: 0.979, total rewards: 25.0\n",
      "Episode: 210, Steps: 335, eps: 0.979, total rewards: 175.0\n",
      "Episode: 211, Steps: 304, eps: 0.979, total rewards: 150.0\n",
      "Episode: 212, Steps: 298, eps: 0.979, total rewards: 50.0\n",
      "Episode: 213, Steps: 414, eps: 0.979, total rewards: 150.0\n",
      "Episode: 214, Steps: 363, eps: 0.979, total rewards: 275.0\n",
      "Episode: 215, Steps: 408, eps: 0.979, total rewards: 300.0\n",
      "Episode: 216, Steps: 319, eps: 0.979, total rewards: 200.0\n",
      "Episode: 217, Steps: 323, eps: 0.978, total rewards: 125.0\n",
      "Episode: 218, Steps: 294, eps: 0.978, total rewards: 150.0\n",
      "Episode: 219, Steps: 380, eps: 0.978, total rewards: 275.0\n",
      "Episode: 220, Steps: 386, eps: 0.978, total rewards: 200.0\n",
      "Episode: 221, Steps: 306, eps: 0.978, total rewards: 25.0\n",
      "Episode: 222, Steps: 416, eps: 0.978, total rewards: 225.0\n",
      "Episode: 223, Steps: 351, eps: 0.978, total rewards: 225.0\n",
      "Episode: 224, Steps: 348, eps: 0.978, total rewards: 125.0\n",
      "Episode: 225, Steps: 323, eps: 0.978, total rewards: 100.0\n",
      "Episode: 226, Steps: 295, eps: 0.978, total rewards: 50.0\n",
      "Episode: 227, Steps: 289, eps: 0.977, total rewards: 0.0\n",
      "Episode: 228, Steps: 327, eps: 0.977, total rewards: 200.0\n",
      "Episode: 229, Steps: 393, eps: 0.977, total rewards: 200.0\n",
      "Episode: 230, Steps: 285, eps: 0.977, total rewards: 0.0\n",
      "Episode: 231, Steps: 311, eps: 0.977, total rewards: 150.0\n",
      "Episode: 232, Steps: 288, eps: 0.977, total rewards: 0.0\n",
      "Episode: 233, Steps: 287, eps: 0.977, total rewards: 0.0\n",
      "Episode: 234, Steps: 321, eps: 0.977, total rewards: 100.0\n",
      "Episode: 235, Steps: 378, eps: 0.977, total rewards: 200.0\n",
      "Episode: 236, Steps: 325, eps: 0.977, total rewards: 175.0\n",
      "Episode: 237, Steps: 293, eps: 0.976, total rewards: 0.0\n",
      "Episode: 238, Steps: 335, eps: 0.976, total rewards: 125.0\n",
      "Episode: 239, Steps: 360, eps: 0.976, total rewards: 100.0\n",
      "Episode: 240, Steps: 277, eps: 0.976, total rewards: 75.0\n",
      "Episode: 241, Steps: 330, eps: 0.976, total rewards: 200.0\n",
      "Episode: 242, Steps: 314, eps: 0.976, total rewards: 200.0\n",
      "Episode: 243, Steps: 320, eps: 0.976, total rewards: 75.0\n",
      "Episode: 244, Steps: 311, eps: 0.976, total rewards: 75.0\n",
      "Episode: 245, Steps: 331, eps: 0.976, total rewards: 100.0\n",
      "Episode: 246, Steps: 302, eps: 0.976, total rewards: 50.0\n",
      "Episode: 247, Steps: 305, eps: 0.975, total rewards: 50.0\n",
      "Episode: 248, Steps: 383, eps: 0.975, total rewards: 450.0\n",
      "Episode: 249, Steps: 265, eps: 0.975, total rewards: 125.0\n",
      "Episode: 250, Steps: 370, eps: 0.975, total rewards: 200.0\n",
      "Episode: 251, Steps: 304, eps: 0.975, total rewards: 25.0\n",
      "Episode: 252, Steps: 346, eps: 0.975, total rewards: 125.0\n",
      "Episode: 253, Steps: 314, eps: 0.975, total rewards: 150.0\n",
      "Episode: 254, Steps: 281, eps: 0.975, total rewards: 100.0\n",
      "Episode: 255, Steps: 389, eps: 0.975, total rewards: 200.0\n",
      "Episode: 256, Steps: 353, eps: 0.975, total rewards: 75.0\n",
      "Episode: 257, Steps: 319, eps: 0.974, total rewards: 200.0\n",
      "Episode: 258, Steps: 388, eps: 0.974, total rewards: 250.0\n",
      "Episode: 259, Steps: 356, eps: 0.974, total rewards: 150.0\n",
      "Episode: 260, Steps: 261, eps: 0.974, total rewards: 50.0\n",
      "Episode: 261, Steps: 431, eps: 0.974, total rewards: 325.0\n",
      "Episode: 262, Steps: 290, eps: 0.974, total rewards: 75.0\n",
      "Episode: 263, Steps: 363, eps: 0.974, total rewards: 250.0\n",
      "Episode: 264, Steps: 339, eps: 0.974, total rewards: 175.0\n",
      "Episode: 265, Steps: 304, eps: 0.974, total rewards: 200.0\n",
      "Episode: 266, Steps: 314, eps: 0.974, total rewards: 175.0\n",
      "Episode: 267, Steps: 297, eps: 0.973, total rewards: 50.0\n",
      "Episode: 268, Steps: 331, eps: 0.973, total rewards: 100.0\n",
      "Episode: 269, Steps: 310, eps: 0.973, total rewards: 50.0\n",
      "Episode: 270, Steps: 324, eps: 0.973, total rewards: 100.0\n",
      "Episode: 271, Steps: 312, eps: 0.973, total rewards: 50.0\n",
      "Episode: 272, Steps: 306, eps: 0.973, total rewards: 175.0\n",
      "Episode: 273, Steps: 450, eps: 0.973, total rewards: 500.0\n",
      "Episode: 274, Steps: 289, eps: 0.973, total rewards: 0.0\n",
      "Episode: 275, Steps: 328, eps: 0.973, total rewards: 225.0\n",
      "Episode: 276, Steps: 381, eps: 0.973, total rewards: 100.0\n",
      "Episode: 277, Steps: 296, eps: 0.972, total rewards: 25.0\n",
      "Episode: 278, Steps: 445, eps: 0.972, total rewards: 250.0\n",
      "Episode: 279, Steps: 327, eps: 0.972, total rewards: 125.0\n",
      "Episode: 280, Steps: 321, eps: 0.972, total rewards: 175.0\n",
      "Episode: 281, Steps: 373, eps: 0.972, total rewards: 175.0\n",
      "Episode: 282, Steps: 279, eps: 0.972, total rewards: 125.0\n",
      "Episode: 283, Steps: 464, eps: 0.972, total rewards: 775.0\n",
      "Episode: 284, Steps: 388, eps: 0.972, total rewards: 150.0\n",
      "Episode: 285, Steps: 265, eps: 0.972, total rewards: 50.0\n",
      "Episode: 286, Steps: 399, eps: 0.972, total rewards: 250.0\n",
      "Episode: 287, Steps: 296, eps: 0.971, total rewards: 25.0\n",
      "Episode: 288, Steps: 295, eps: 0.971, total rewards: 25.0\n",
      "Episode: 289, Steps: 305, eps: 0.971, total rewards: 75.0\n",
      "Episode: 290, Steps: 380, eps: 0.971, total rewards: 150.0\n",
      "Episode: 291, Steps: 356, eps: 0.971, total rewards: 200.0\n",
      "Episode: 292, Steps: 403, eps: 0.971, total rewards: 475.0\n",
      "Episode: 293, Steps: 278, eps: 0.971, total rewards: 75.0\n",
      "Episode: 294, Steps: 279, eps: 0.971, total rewards: 75.0\n",
      "Episode: 295, Steps: 375, eps: 0.971, total rewards: 475.0\n",
      "Episode: 296, Steps: 312, eps: 0.971, total rewards: 50.0\n",
      "Episode: 297, Steps: 294, eps: 0.970, total rewards: 25.0\n",
      "Episode: 298, Steps: 321, eps: 0.970, total rewards: 75.0\n",
      "Episode: 299, Steps: 326, eps: 0.970, total rewards: 100.0\n",
      "Episode: 300, Steps: 370, eps: 0.970, total rewards: 125.0\n",
      "Episode: 301, Steps: 330, eps: 0.970, total rewards: 75.0\n",
      "Episode: 302, Steps: 299, eps: 0.970, total rewards: 75.0\n",
      "Episode: 303, Steps: 279, eps: 0.970, total rewards: 50.0\n",
      "Episode: 304, Steps: 328, eps: 0.970, total rewards: 100.0\n",
      "Episode: 305, Steps: 333, eps: 0.970, total rewards: 100.0\n",
      "Episode: 306, Steps: 342, eps: 0.970, total rewards: 175.0\n",
      "Episode: 307, Steps: 347, eps: 0.969, total rewards: 200.0\n",
      "Episode: 308, Steps: 311, eps: 0.969, total rewards: 75.0\n",
      "Episode: 309, Steps: 272, eps: 0.969, total rewards: 75.0\n",
      "Episode: 310, Steps: 370, eps: 0.969, total rewards: 175.0\n",
      "Episode: 311, Steps: 379, eps: 0.969, total rewards: 250.0\n",
      "Episode: 312, Steps: 482, eps: 0.969, total rewards: 350.0\n",
      "Episode: 313, Steps: 366, eps: 0.969, total rewards: 300.0\n",
      "Episode: 314, Steps: 288, eps: 0.969, total rewards: 0.0\n",
      "Episode: 315, Steps: 545, eps: 0.969, total rewards: 850.0\n",
      "Episode: 316, Steps: 359, eps: 0.969, total rewards: 150.0\n",
      "Episode: 317, Steps: 326, eps: 0.968, total rewards: 100.0\n",
      "Episode: 318, Steps: 306, eps: 0.968, total rewards: 100.0\n",
      "Episode: 319, Steps: 347, eps: 0.968, total rewards: 175.0\n",
      "Episode: 320, Steps: 333, eps: 0.968, total rewards: 75.0\n",
      "Episode: 321, Steps: 328, eps: 0.968, total rewards: 100.0\n",
      "Episode: 322, Steps: 315, eps: 0.968, total rewards: 75.0\n",
      "Episode: 323, Steps: 311, eps: 0.968, total rewards: 50.0\n",
      "Episode: 324, Steps: 357, eps: 0.968, total rewards: 200.0\n",
      "Episode: 325, Steps: 404, eps: 0.968, total rewards: 225.0\n",
      "Episode: 326, Steps: 290, eps: 0.968, total rewards: 25.0\n",
      "Episode: 327, Steps: 332, eps: 0.967, total rewards: 100.0\n",
      "Episode: 328, Steps: 320, eps: 0.967, total rewards: 75.0\n",
      "Episode: 329, Steps: 286, eps: 0.967, total rewards: 0.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "File \u001B[0;32m~/.local/share/virtualenvs/rl-atari-7yjpj432/lib/python3.11/site-packages/tensorflow/python/ops/array_ops.py:4958\u001B[0m, in \u001B[0;36mgather\u001B[0;34m(***failed resolving arguments***)\u001B[0m\n\u001B[1;32m   4955\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   4956\u001B[0m   \u001B[38;5;66;03m# TODO(apassos) find a less bad way of detecting resource variables\u001B[39;00m\n\u001B[1;32m   4957\u001B[0m   \u001B[38;5;66;03m# without introducing a circular dependency.\u001B[39;00m\n\u001B[0;32m-> 4958\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mparams\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msparse_read\u001B[49m(indices, name\u001B[38;5;241m=\u001B[39mname)\n\u001B[1;32m   4959\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m:\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/rl-atari-7yjpj432/lib/python3.11/site-packages/tensorflow/python/framework/tensor.py:260\u001B[0m, in \u001B[0;36mTensor.__getattr__\u001B[0;34m(self, name)\u001B[0m\n\u001B[1;32m    255\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m(\n\u001B[1;32m    256\u001B[0m       \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(\u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m object has no attribute \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m. \u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m\"\"\"\u001B[39m\n\u001B[1;32m    257\u001B[0m \u001B[38;5;124m    If you are looking for numpy-related methods, please run the following:\u001B[39m\n\u001B[1;32m    258\u001B[0m \u001B[38;5;124m    tf.experimental.numpy.experimental_enable_numpy_behavior()\u001B[39m\n\u001B[1;32m    259\u001B[0m \u001B[38;5;124m  \u001B[39m\u001B[38;5;124m\"\"\"\u001B[39m)\n\u001B[0;32m--> 260\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[38;5;21;43m__getattribute__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mAttributeError\u001B[0m: 'SymbolicTensor' object has no attribute 'sparse_read'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[2], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m qbert_rewards, qbert_max_steps, qbert_q_values, qbert_losses, qbert_model \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_dqn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mALE/Qbert-v5\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mdqn\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/rl-atari/src/main.py:79\u001B[0m, in \u001B[0;36mtrain_dqn\u001B[0;34m(env_name, method, n_episodes, n_steps, discount_factor, initial_learning_rate, final_learning_rate, model_seed, env_seed, replay_buff_max_len, initial_training_percentage, eta, alpha, plasticity_training_epsilon, restore_best_weights, loss_fn)\u001B[0m\n\u001B[1;32m     76\u001B[0m target_model\u001B[38;5;241m.\u001B[39mset_weights(model\u001B[38;5;241m.\u001B[39mget_weights())\n\u001B[1;32m     78\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m method \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdqn\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m method \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mddqn\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m---> 79\u001B[0m     rewards_per_episode, steps_over_episode, q_values_over_episode, losses \u001B[38;5;241m=\u001B[39m \u001B[43mplay_multiple_episodes_dqn\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     80\u001B[0m \u001B[43m        \u001B[49m\u001B[43menv\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43menv\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     81\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     82\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtarget_model\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     83\u001B[0m \u001B[43m        \u001B[49m\u001B[43mn_episodes\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_episodes\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     84\u001B[0m \u001B[43m        \u001B[49m\u001B[43mn_steps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_steps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     85\u001B[0m \u001B[43m        \u001B[49m\u001B[43mn_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maction_count\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     86\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhistory_len\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mHISTORY_LEN\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     87\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdiscount_factor\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdiscount_factor\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     88\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mBATCH_SIZE\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     89\u001B[0m \u001B[43m        \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     90\u001B[0m \u001B[43m        \u001B[49m\u001B[43mloss_fn\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mloss_fn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     91\u001B[0m \u001B[43m        \u001B[49m\u001B[43mframe_shape\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mFRAME_SHAPE\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     92\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreplay_buff_max_len\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreplay_buff_max_len\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     93\u001B[0m \u001B[43m        \u001B[49m\u001B[43mrestore_best_weights\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrestore_best_weights\u001B[49m\n\u001B[1;32m     94\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     95\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m method \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mddqn_injected_plasticity\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[1;32m     96\u001B[0m     rewards_per_episode, steps_over_episode, q_values_over_episode, losses \u001B[38;5;241m=\u001B[39m play_multiple_episodes_dqn_plastic(\n\u001B[1;32m     97\u001B[0m         env\u001B[38;5;241m=\u001B[39menv,\n\u001B[1;32m     98\u001B[0m         model\u001B[38;5;241m=\u001B[39mmodel,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    112\u001B[0m         restore_best_weights\u001B[38;5;241m=\u001B[39mrestore_best_weights\n\u001B[1;32m    113\u001B[0m     )\n",
      "File \u001B[0;32m~/PycharmProjects/rl-atari/src/agents/dqn_agent.py:40\u001B[0m, in \u001B[0;36mplay_multiple_episodes_dqn\u001B[0;34m(env, model, target_model, n_episodes, n_steps, n_outputs, history_len, discount_factor, batch_size, optimizer, loss_fn, frame_shape, replay_buff_max_len, restore_best_weights)\u001B[0m\n\u001B[1;32m     37\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m episode \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(n_episodes):\n\u001B[1;32m     38\u001B[0m     epsilon \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mmax\u001B[39m(\u001B[38;5;241m1\u001B[39m \u001B[38;5;241m-\u001B[39m episode \u001B[38;5;241m/\u001B[39m n_episodes, \u001B[38;5;241m0.01\u001B[39m)\n\u001B[0;32m---> 40\u001B[0m     episode_reward, max_step_of_episode \u001B[38;5;241m=\u001B[39m \u001B[43mplay_one_episode\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     41\u001B[0m \u001B[43m        \u001B[49m\u001B[43mepisode_idx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mepisode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     42\u001B[0m \u001B[43m        \u001B[49m\u001B[43menv\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43menv\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     43\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     44\u001B[0m \u001B[43m        \u001B[49m\u001B[43mn_steps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_steps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     45\u001B[0m \u001B[43m        \u001B[49m\u001B[43mn_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mn_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     46\u001B[0m \u001B[43m        \u001B[49m\u001B[43mepsilon\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mepsilon\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     47\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreplay_buffer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreplay_buffer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     48\u001B[0m \u001B[43m        \u001B[49m\u001B[43mhistory_len\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mhistory_len\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     49\u001B[0m \u001B[43m        \u001B[49m\u001B[43mframe_shape\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mframe_shape\u001B[49m\n\u001B[1;32m     50\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     52\u001B[0m     rewards_over_episodes\u001B[38;5;241m.\u001B[39mappend(episode_reward)\n\u001B[1;32m     53\u001B[0m     steps_over_episodes\u001B[38;5;241m.\u001B[39mappend(max_step_of_episode)\n",
      "File \u001B[0;32m~/PycharmProjects/rl-atari/src/agents/dqn_agent.py:113\u001B[0m, in \u001B[0;36mplay_one_episode\u001B[0;34m(episode_idx, env, model, n_steps, n_outputs, epsilon, replay_buffer, history_len, frame_shape)\u001B[0m\n\u001B[1;32m    110\u001B[0m max_step \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m    112\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m step \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(n_steps):\n\u001B[0;32m--> 113\u001B[0m     reward, done, truncated, info \u001B[38;5;241m=\u001B[39m \u001B[43mplay_one_step\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    114\u001B[0m \u001B[43m        \u001B[49m\u001B[43menv\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    115\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstate_queue\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    116\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    117\u001B[0m \u001B[43m        \u001B[49m\u001B[43mn_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    118\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreplay_buffer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    119\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstep\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    120\u001B[0m \u001B[43m        \u001B[49m\u001B[43mepsilon\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    121\u001B[0m \u001B[43m        \u001B[49m\u001B[43mframe_shape\u001B[49m\n\u001B[1;32m    122\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    124\u001B[0m     max_step \u001B[38;5;241m=\u001B[39m step\n\u001B[1;32m    125\u001B[0m     episode_rewards\u001B[38;5;241m.\u001B[39mappend(reward)\n",
      "File \u001B[0;32m~/PycharmProjects/rl-atari/src/agents/dqn_agent.py:87\u001B[0m, in \u001B[0;36mplay_one_step\u001B[0;34m(env, state_queue, model, n_outputs, replay_buffer, step_idx, epsilon, frame_shape)\u001B[0m\n\u001B[1;32m     85\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mplay_one_step\u001B[39m(env, state_queue, model, n_outputs, replay_buffer, step_idx, epsilon, frame_shape):\n\u001B[1;32m     86\u001B[0m     state_history \u001B[38;5;241m=\u001B[39m state_queue\u001B[38;5;241m.\u001B[39mget_history()\n\u001B[0;32m---> 87\u001B[0m     action \u001B[38;5;241m=\u001B[39m \u001B[43mepsilon_greedy_policy\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstate_history\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_outputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepsilon\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     88\u001B[0m     next_state, reward, done, truncated, info \u001B[38;5;241m=\u001B[39m env\u001B[38;5;241m.\u001B[39mstep(action)\n\u001B[1;32m     90\u001B[0m     last_state \u001B[38;5;241m=\u001B[39m state_history[:, :, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m][\u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;241m.\u001B[39m, np\u001B[38;5;241m.\u001B[39mnewaxis]\n",
      "File \u001B[0;32m~/PycharmProjects/rl-atari/src/policy.py:8\u001B[0m, in \u001B[0;36mepsilon_greedy_policy\u001B[0;34m(state_history, model, n_outputs, epsilon)\u001B[0m\n\u001B[1;32m      6\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m np\u001B[38;5;241m.\u001B[39mrandom\u001B[38;5;241m.\u001B[39mrandint(n_outputs)\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m----> 8\u001B[0m     Q_values \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstate_history\u001B[49m\u001B[43m[\u001B[49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnewaxis\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m      9\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m Q_values\u001B[38;5;241m.\u001B[39margmax()\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/rl-atari-7yjpj432/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:117\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    115\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    116\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 117\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    118\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    119\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/rl-atari-7yjpj432/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py:457\u001B[0m, in \u001B[0;36mTensorFlowTrainer.predict\u001B[0;34m(self, x, batch_size, verbose, steps, callbacks)\u001B[0m\n\u001B[1;32m    452\u001B[0m \u001B[38;5;129m@traceback_utils\u001B[39m\u001B[38;5;241m.\u001B[39mfilter_traceback\n\u001B[1;32m    453\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpredict\u001B[39m(\n\u001B[1;32m    454\u001B[0m     \u001B[38;5;28mself\u001B[39m, x, batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, verbose\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mauto\u001B[39m\u001B[38;5;124m\"\u001B[39m, steps\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, callbacks\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    455\u001B[0m ):\n\u001B[1;32m    456\u001B[0m     \u001B[38;5;66;03m# Create an iterator that yields batches of input data.\u001B[39;00m\n\u001B[0;32m--> 457\u001B[0m     epoch_iterator \u001B[38;5;241m=\u001B[39m \u001B[43mTFEpochIterator\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    458\u001B[0m \u001B[43m        \u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    459\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    460\u001B[0m \u001B[43m        \u001B[49m\u001B[43msteps_per_epoch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msteps\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    461\u001B[0m \u001B[43m        \u001B[49m\u001B[43mshuffle\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    462\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdistribute_strategy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdistribute_strategy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    463\u001B[0m \u001B[43m        \u001B[49m\u001B[43msteps_per_execution\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msteps_per_execution\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    464\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    466\u001B[0m     \u001B[38;5;66;03m# Container that configures and calls callbacks.\u001B[39;00m\n\u001B[1;32m    467\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(callbacks, callbacks_module\u001B[38;5;241m.\u001B[39mCallbackList):\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/rl-atari-7yjpj432/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py:640\u001B[0m, in \u001B[0;36mTFEpochIterator.__init__\u001B[0;34m(self, distribute_strategy, *args, **kwargs)\u001B[0m\n\u001B[1;32m    638\u001B[0m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    639\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_distribute_strategy \u001B[38;5;241m=\u001B[39m distribute_strategy\n\u001B[0;32m--> 640\u001B[0m dataset \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_iterator\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    641\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(dataset, tf\u001B[38;5;241m.\u001B[39mdistribute\u001B[38;5;241m.\u001B[39mDistributedDataset):\n\u001B[1;32m    642\u001B[0m     dataset \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_distribute_strategy\u001B[38;5;241m.\u001B[39mexperimental_distribute_dataset(\n\u001B[1;32m    643\u001B[0m         dataset\n\u001B[1;32m    644\u001B[0m     )\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/rl-atari-7yjpj432/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py:649\u001B[0m, in \u001B[0;36mTFEpochIterator._get_iterator\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    648\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_get_iterator\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m--> 649\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdata_adapter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_tf_dataset\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/rl-atari-7yjpj432/lib/python3.11/site-packages/keras/src/trainers/data_adapters/array_data_adapter.py:236\u001B[0m, in \u001B[0;36mArrayDataAdapter.get_tf_dataset\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    233\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m shuffle \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbatch\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m    234\u001B[0m     indices_dataset \u001B[38;5;241m=\u001B[39m indices_dataset\u001B[38;5;241m.\u001B[39mmap(tf\u001B[38;5;241m.\u001B[39mrandom\u001B[38;5;241m.\u001B[39mshuffle)\n\u001B[0;32m--> 236\u001B[0m dataset \u001B[38;5;241m=\u001B[39m \u001B[43mslice_inputs\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindices_dataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_inputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    238\u001B[0m options \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mOptions()\n\u001B[1;32m    239\u001B[0m options\u001B[38;5;241m.\u001B[39mexperimental_distribute\u001B[38;5;241m.\u001B[39mauto_shard_policy \u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m    240\u001B[0m     tf\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mAutoShardPolicy\u001B[38;5;241m.\u001B[39mDATA\n\u001B[1;32m    241\u001B[0m )\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/rl-atari-7yjpj432/lib/python3.11/site-packages/keras/src/trainers/data_adapters/array_data_adapter.py:215\u001B[0m, in \u001B[0;36mArrayDataAdapter.get_tf_dataset.<locals>.slice_inputs\u001B[0;34m(indices_dataset, inputs)\u001B[0m\n\u001B[1;32m    211\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m x\n\u001B[1;32m    213\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m tree\u001B[38;5;241m.\u001B[39mtraverse(grab_one, data)\n\u001B[0;32m--> 215\u001B[0m dataset \u001B[38;5;241m=\u001B[39m \u001B[43mdataset\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmap\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    216\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgrab_batch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_parallel_calls\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mAUTOTUNE\u001B[49m\n\u001B[1;32m    217\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    219\u001B[0m \u001B[38;5;66;03m# Default optimizations are disabled to avoid the overhead of\u001B[39;00m\n\u001B[1;32m    220\u001B[0m \u001B[38;5;66;03m# (unnecessary) input pipeline graph serialization & deserialization\u001B[39;00m\n\u001B[1;32m    221\u001B[0m options \u001B[38;5;241m=\u001B[39m tf\u001B[38;5;241m.\u001B[39mdata\u001B[38;5;241m.\u001B[39mOptions()\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/rl-atari-7yjpj432/lib/python3.11/site-packages/tensorflow/python/data/ops/dataset_ops.py:2299\u001B[0m, in \u001B[0;36mDatasetV2.map\u001B[0;34m(self, map_func, num_parallel_calls, deterministic, name)\u001B[0m\n\u001B[1;32m   2295\u001B[0m \u001B[38;5;66;03m# Loaded lazily due to a circular dependency (dataset_ops -> map_op ->\u001B[39;00m\n\u001B[1;32m   2296\u001B[0m \u001B[38;5;66;03m# dataset_ops).\u001B[39;00m\n\u001B[1;32m   2297\u001B[0m \u001B[38;5;66;03m# pylint: disable=g-import-not-at-top,protected-access\u001B[39;00m\n\u001B[1;32m   2298\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtensorflow\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpython\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mops\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m map_op\n\u001B[0;32m-> 2299\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mmap_op\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_map_v2\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   2300\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2301\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmap_func\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2302\u001B[0m \u001B[43m    \u001B[49m\u001B[43mnum_parallel_calls\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_parallel_calls\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2303\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdeterministic\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdeterministic\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   2304\u001B[0m \u001B[43m    \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/rl-atari-7yjpj432/lib/python3.11/site-packages/tensorflow/python/data/ops/map_op.py:40\u001B[0m, in \u001B[0;36m_map_v2\u001B[0;34m(input_dataset, map_func, num_parallel_calls, deterministic, name)\u001B[0m\n\u001B[1;32m     37\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m _MapDataset(\n\u001B[1;32m     38\u001B[0m       input_dataset, map_func, preserve_cardinality\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, name\u001B[38;5;241m=\u001B[39mname)\n\u001B[1;32m     39\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 40\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_ParallelMapDataset\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     41\u001B[0m \u001B[43m      \u001B[49m\u001B[43minput_dataset\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     42\u001B[0m \u001B[43m      \u001B[49m\u001B[43mmap_func\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     43\u001B[0m \u001B[43m      \u001B[49m\u001B[43mnum_parallel_calls\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_parallel_calls\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     44\u001B[0m \u001B[43m      \u001B[49m\u001B[43mdeterministic\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdeterministic\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     45\u001B[0m \u001B[43m      \u001B[49m\u001B[43mpreserve_cardinality\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m     46\u001B[0m \u001B[43m      \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/rl-atari-7yjpj432/lib/python3.11/site-packages/tensorflow/python/data/ops/map_op.py:148\u001B[0m, in \u001B[0;36m_ParallelMapDataset.__init__\u001B[0;34m(self, input_dataset, map_func, num_parallel_calls, deterministic, use_inter_op_parallelism, preserve_cardinality, use_legacy_function, name)\u001B[0m\n\u001B[1;32m    146\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_input_dataset \u001B[38;5;241m=\u001B[39m input_dataset\n\u001B[1;32m    147\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_use_inter_op_parallelism \u001B[38;5;241m=\u001B[39m use_inter_op_parallelism\n\u001B[0;32m--> 148\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_map_func \u001B[38;5;241m=\u001B[39m \u001B[43mstructured_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mStructuredFunctionWrapper\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    149\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmap_func\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    150\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_transformation_name\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    151\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdataset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_dataset\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    152\u001B[0m \u001B[43m    \u001B[49m\u001B[43muse_legacy_function\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43muse_legacy_function\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    153\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m deterministic \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    154\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_deterministic \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdefault\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/rl-atari-7yjpj432/lib/python3.11/site-packages/tensorflow/python/data/ops/structured_function.py:265\u001B[0m, in \u001B[0;36mStructuredFunctionWrapper.__init__\u001B[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001B[0m\n\u001B[1;32m    258\u001B[0m       warnings\u001B[38;5;241m.\u001B[39mwarn(\n\u001B[1;32m    259\u001B[0m           \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEven though the `tf.config.experimental_run_functions_eagerly` \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    260\u001B[0m           \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124moption is set, this option does not apply to tf.data functions. \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    261\u001B[0m           \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTo force eager execution of tf.data functions, please use \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    262\u001B[0m           \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`tf.data.experimental.enable_debug_mode()`.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    263\u001B[0m     fn_factory \u001B[38;5;241m=\u001B[39m trace_tf_function(defun_kwargs)\n\u001B[0;32m--> 265\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_function \u001B[38;5;241m=\u001B[39m \u001B[43mfn_factory\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    266\u001B[0m \u001B[38;5;66;03m# There is no graph to add in eager mode.\u001B[39;00m\n\u001B[1;32m    267\u001B[0m add_to_graph \u001B[38;5;241m&\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m context\u001B[38;5;241m.\u001B[39mexecuting_eagerly()\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/rl-atari-7yjpj432/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:1251\u001B[0m, in \u001B[0;36mFunction.get_concrete_function\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1249\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_concrete_function\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m   1250\u001B[0m   \u001B[38;5;66;03m# Implements PolymorphicFunction.get_concrete_function.\u001B[39;00m\n\u001B[0;32m-> 1251\u001B[0m   concrete \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_concrete_function_garbage_collected\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1252\u001B[0m   concrete\u001B[38;5;241m.\u001B[39m_garbage_collector\u001B[38;5;241m.\u001B[39mrelease()  \u001B[38;5;66;03m# pylint: disable=protected-access\u001B[39;00m\n\u001B[1;32m   1253\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m concrete\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/rl-atari-7yjpj432/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:1221\u001B[0m, in \u001B[0;36mFunction._get_concrete_function_garbage_collected\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1219\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_variable_creation_config \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   1220\u001B[0m     initializers \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m-> 1221\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_initialize\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43madd_initializers_to\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minitializers\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1222\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_initialize_uninitialized_variables(initializers)\n\u001B[1;32m   1224\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_created_variables:\n\u001B[1;32m   1225\u001B[0m   \u001B[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001B[39;00m\n\u001B[1;32m   1226\u001B[0m   \u001B[38;5;66;03m# version which is guaranteed to never create variables.\u001B[39;00m\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/rl-atari-7yjpj432/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:696\u001B[0m, in \u001B[0;36mFunction._initialize\u001B[0;34m(self, args, kwds, add_initializers_to)\u001B[0m\n\u001B[1;32m    691\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_variable_creation_config \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_generate_scoped_tracing_options(\n\u001B[1;32m    692\u001B[0m     variable_capturing_scope,\n\u001B[1;32m    693\u001B[0m     tracing_compilation\u001B[38;5;241m.\u001B[39mScopeType\u001B[38;5;241m.\u001B[39mVARIABLE_CREATION,\n\u001B[1;32m    694\u001B[0m )\n\u001B[1;32m    695\u001B[0m \u001B[38;5;66;03m# Force the definition of the function for these arguments\u001B[39;00m\n\u001B[0;32m--> 696\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_concrete_variable_creation_fn \u001B[38;5;241m=\u001B[39m \u001B[43mtracing_compilation\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrace_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    697\u001B[0m \u001B[43m    \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_variable_creation_config\u001B[49m\n\u001B[1;32m    698\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    700\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21minvalid_creator_scope\u001B[39m(\u001B[38;5;241m*\u001B[39munused_args, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39munused_kwds):\n\u001B[1;32m    701\u001B[0m \u001B[38;5;250m  \u001B[39m\u001B[38;5;124;03m\"\"\"Disables variable creation.\"\"\"\u001B[39;00m\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/rl-atari-7yjpj432/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:178\u001B[0m, in \u001B[0;36mtrace_function\u001B[0;34m(args, kwargs, tracing_options)\u001B[0m\n\u001B[1;32m    175\u001B[0m     args \u001B[38;5;241m=\u001B[39m tracing_options\u001B[38;5;241m.\u001B[39minput_signature\n\u001B[1;32m    176\u001B[0m     kwargs \u001B[38;5;241m=\u001B[39m {}\n\u001B[0;32m--> 178\u001B[0m   concrete_function \u001B[38;5;241m=\u001B[39m \u001B[43m_maybe_define_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    179\u001B[0m \u001B[43m      \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtracing_options\u001B[49m\n\u001B[1;32m    180\u001B[0m \u001B[43m  \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    182\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m tracing_options\u001B[38;5;241m.\u001B[39mbind_graph_to_function:\n\u001B[1;32m    183\u001B[0m   concrete_function\u001B[38;5;241m.\u001B[39m_garbage_collector\u001B[38;5;241m.\u001B[39mrelease()  \u001B[38;5;66;03m# pylint: disable=protected-access\u001B[39;00m\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/rl-atari-7yjpj432/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:283\u001B[0m, in \u001B[0;36m_maybe_define_function\u001B[0;34m(args, kwargs, tracing_options)\u001B[0m\n\u001B[1;32m    281\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    282\u001B[0m   target_func_type \u001B[38;5;241m=\u001B[39m lookup_func_type\n\u001B[0;32m--> 283\u001B[0m concrete_function \u001B[38;5;241m=\u001B[39m \u001B[43m_create_concrete_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    284\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtarget_func_type\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlookup_func_context\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunc_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtracing_options\u001B[49m\n\u001B[1;32m    285\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    287\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m tracing_options\u001B[38;5;241m.\u001B[39mfunction_cache \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    288\u001B[0m   tracing_options\u001B[38;5;241m.\u001B[39mfunction_cache\u001B[38;5;241m.\u001B[39madd(\n\u001B[1;32m    289\u001B[0m       concrete_function, current_func_context\n\u001B[1;32m    290\u001B[0m   )\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/rl-atari-7yjpj432/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:310\u001B[0m, in \u001B[0;36m_create_concrete_function\u001B[0;34m(function_type, type_context, func_graph, tracing_options)\u001B[0m\n\u001B[1;32m    303\u001B[0m   placeholder_bound_args \u001B[38;5;241m=\u001B[39m function_type\u001B[38;5;241m.\u001B[39mplaceholder_arguments(\n\u001B[1;32m    304\u001B[0m       placeholder_context\n\u001B[1;32m    305\u001B[0m   )\n\u001B[1;32m    307\u001B[0m disable_acd \u001B[38;5;241m=\u001B[39m tracing_options\u001B[38;5;241m.\u001B[39mattributes \u001B[38;5;129;01mand\u001B[39;00m tracing_options\u001B[38;5;241m.\u001B[39mattributes\u001B[38;5;241m.\u001B[39mget(\n\u001B[1;32m    308\u001B[0m     attributes_lib\u001B[38;5;241m.\u001B[39mDISABLE_ACD, \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m    309\u001B[0m )\n\u001B[0;32m--> 310\u001B[0m traced_func_graph \u001B[38;5;241m=\u001B[39m \u001B[43mfunc_graph_module\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunc_graph_from_py_func\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    311\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtracing_options\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    312\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtracing_options\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpython_function\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    313\u001B[0m \u001B[43m    \u001B[49m\u001B[43mplaceholder_bound_args\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    314\u001B[0m \u001B[43m    \u001B[49m\u001B[43mplaceholder_bound_args\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    315\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    316\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfunc_graph\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfunc_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    317\u001B[0m \u001B[43m    \u001B[49m\u001B[43madd_control_dependencies\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;129;43;01mnot\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mdisable_acd\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    318\u001B[0m \u001B[43m    \u001B[49m\u001B[43marg_names\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfunction_type_utils\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto_arg_names\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfunction_type\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    319\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcreate_placeholders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    320\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    322\u001B[0m transform\u001B[38;5;241m.\u001B[39mapply_func_graph_transforms(traced_func_graph)\n\u001B[1;32m    324\u001B[0m graph_capture_container \u001B[38;5;241m=\u001B[39m traced_func_graph\u001B[38;5;241m.\u001B[39mfunction_captures\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/rl-atari-7yjpj432/lib/python3.11/site-packages/tensorflow/python/framework/func_graph.py:1059\u001B[0m, in \u001B[0;36mfunc_graph_from_py_func\u001B[0;34m(name, python_func, args, kwargs, signature, func_graph, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders)\u001B[0m\n\u001B[1;32m   1056\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m x\n\u001B[1;32m   1058\u001B[0m _, original_func \u001B[38;5;241m=\u001B[39m tf_decorator\u001B[38;5;241m.\u001B[39munwrap(python_func)\n\u001B[0;32m-> 1059\u001B[0m func_outputs \u001B[38;5;241m=\u001B[39m \u001B[43mpython_func\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfunc_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfunc_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1061\u001B[0m \u001B[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001B[39;00m\n\u001B[1;32m   1062\u001B[0m \u001B[38;5;66;03m# TensorArrays and `None`s.\u001B[39;00m\n\u001B[1;32m   1063\u001B[0m func_outputs \u001B[38;5;241m=\u001B[39m variable_utils\u001B[38;5;241m.\u001B[39mconvert_variables_to_tensors(func_outputs)\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/rl-atari-7yjpj432/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:599\u001B[0m, in \u001B[0;36mFunction._generate_scoped_tracing_options.<locals>.wrapped_fn\u001B[0;34m(*args, **kwds)\u001B[0m\n\u001B[1;32m    595\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m default_graph\u001B[38;5;241m.\u001B[39m_variable_creator_scope(scope, priority\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m50\u001B[39m):  \u001B[38;5;66;03m# pylint: disable=protected-access\u001B[39;00m\n\u001B[1;32m    596\u001B[0m   \u001B[38;5;66;03m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001B[39;00m\n\u001B[1;32m    597\u001B[0m   \u001B[38;5;66;03m# the function a weak reference to itself to avoid a reference cycle.\u001B[39;00m\n\u001B[1;32m    598\u001B[0m   \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(compile_with_xla):\n\u001B[0;32m--> 599\u001B[0m     out \u001B[38;5;241m=\u001B[39m \u001B[43mweak_wrapped_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m__wrapped__\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    600\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m out\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/rl-atari-7yjpj432/lib/python3.11/site-packages/tensorflow/python/data/ops/structured_function.py:231\u001B[0m, in \u001B[0;36mStructuredFunctionWrapper.__init__.<locals>.trace_tf_function.<locals>.wrapped_fn\u001B[0;34m(*args)\u001B[0m\n\u001B[1;32m    230\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapped_fn\u001B[39m(\u001B[38;5;241m*\u001B[39margs):  \u001B[38;5;66;03m# pylint: disable=missing-docstring\u001B[39;00m\n\u001B[0;32m--> 231\u001B[0m   ret \u001B[38;5;241m=\u001B[39m \u001B[43mwrapper_helper\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    232\u001B[0m   ret \u001B[38;5;241m=\u001B[39m structure\u001B[38;5;241m.\u001B[39mto_tensor_list(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_output_structure, ret)\n\u001B[1;32m    233\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m [ops\u001B[38;5;241m.\u001B[39mconvert_to_tensor(t) \u001B[38;5;28;01mfor\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m ret]\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/rl-atari-7yjpj432/lib/python3.11/site-packages/tensorflow/python/data/ops/structured_function.py:161\u001B[0m, in \u001B[0;36mStructuredFunctionWrapper.__init__.<locals>.wrapper_helper\u001B[0;34m(*args)\u001B[0m\n\u001B[1;32m    159\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m _should_unpack(nested_args):\n\u001B[1;32m    160\u001B[0m   nested_args \u001B[38;5;241m=\u001B[39m (nested_args,)\n\u001B[0;32m--> 161\u001B[0m ret \u001B[38;5;241m=\u001B[39m \u001B[43mautograph\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtf_convert\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_func\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mag_ctx\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mnested_args\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    162\u001B[0m ret \u001B[38;5;241m=\u001B[39m variable_utils\u001B[38;5;241m.\u001B[39mconvert_variables_to_tensors(ret)\n\u001B[1;32m    163\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m _should_pack(ret):\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/rl-atari-7yjpj432/lib/python3.11/site-packages/tensorflow/python/autograph/impl/api.py:690\u001B[0m, in \u001B[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    688\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    689\u001B[0m   \u001B[38;5;28;01mwith\u001B[39;00m conversion_ctx:\n\u001B[0;32m--> 690\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mconverted_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    691\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:  \u001B[38;5;66;03m# pylint:disable=broad-except\u001B[39;00m\n\u001B[1;32m    692\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(e, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mag_error_metadata\u001B[39m\u001B[38;5;124m'\u001B[39m):\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/rl-atari-7yjpj432/lib/python3.11/site-packages/tensorflow/python/autograph/impl/api.py:377\u001B[0m, in \u001B[0;36mconverted_call\u001B[0;34m(f, args, kwargs, caller_fn_scope, options)\u001B[0m\n\u001B[1;32m    374\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m _call_unconverted(f, args, kwargs, options)\n\u001B[1;32m    376\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m options\u001B[38;5;241m.\u001B[39muser_requested \u001B[38;5;129;01mand\u001B[39;00m conversion\u001B[38;5;241m.\u001B[39mis_allowlisted(f):\n\u001B[0;32m--> 377\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_call_unconverted\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptions\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    379\u001B[0m \u001B[38;5;66;03m# internal_convert_user_code is for example turned off when issuing a dynamic\u001B[39;00m\n\u001B[1;32m    380\u001B[0m \u001B[38;5;66;03m# call conversion from generated code while in nonrecursive mode. In that\u001B[39;00m\n\u001B[1;32m    381\u001B[0m \u001B[38;5;66;03m# case we evidently don't want to recurse, but we still have to convert\u001B[39;00m\n\u001B[1;32m    382\u001B[0m \u001B[38;5;66;03m# things like builtins.\u001B[39;00m\n\u001B[1;32m    383\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m options\u001B[38;5;241m.\u001B[39minternal_convert_user_code:\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/rl-atari-7yjpj432/lib/python3.11/site-packages/tensorflow/python/autograph/impl/api.py:459\u001B[0m, in \u001B[0;36m_call_unconverted\u001B[0;34m(f, args, kwargs, options, update_cache)\u001B[0m\n\u001B[1;32m    456\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m f\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__self__\u001B[39m\u001B[38;5;241m.\u001B[39mcall(args, kwargs)\n\u001B[1;32m    458\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m kwargs \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 459\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mf\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    460\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m f(\u001B[38;5;241m*\u001B[39margs)\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/rl-atari-7yjpj432/lib/python3.11/site-packages/keras/src/trainers/data_adapters/array_data_adapter.py:213\u001B[0m, in \u001B[0;36mArrayDataAdapter.get_tf_dataset.<locals>.slice_inputs.<locals>.grab_batch\u001B[0;34m(i, data)\u001B[0m\n\u001B[1;32m    210\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mgather(x, i, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m    211\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m x\n\u001B[0;32m--> 213\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtree\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtraverse\u001B[49m\u001B[43m(\u001B[49m\u001B[43mgrab_one\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/rl-atari-7yjpj432/lib/python3.11/site-packages/keras/src/utils/tree.py:110\u001B[0m, in \u001B[0;36mtraverse\u001B[0;34m(func, structure, top_down)\u001B[0m\n\u001B[1;32m    104\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m optree\u001B[38;5;241m.\u001B[39mtree_unflatten(\n\u001B[1;32m    105\u001B[0m             treedef,\n\u001B[1;32m    106\u001B[0m             [traverse(func, c, top_down\u001B[38;5;241m=\u001B[39mtop_down) \u001B[38;5;28;01mfor\u001B[39;00m c \u001B[38;5;129;01min\u001B[39;00m children],\n\u001B[1;32m    107\u001B[0m         )\n\u001B[1;32m    109\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m top_down:\n\u001B[0;32m--> 110\u001B[0m     ret \u001B[38;5;241m=\u001B[39m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstructure\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    111\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m ret \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    112\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m traverse_children()\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/rl-atari-7yjpj432/lib/python3.11/site-packages/keras/src/trainers/data_adapters/array_data_adapter.py:210\u001B[0m, in \u001B[0;36mArrayDataAdapter.get_tf_dataset.<locals>.slice_inputs.<locals>.grab_batch.<locals>.grab_one\u001B[0;34m(x)\u001B[0m\n\u001B[1;32m    208\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    209\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mis_tensor(x):\n\u001B[0;32m--> 210\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgather\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mi\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    211\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m x\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/rl-atari-7yjpj432/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/rl-atari-7yjpj432/lib/python3.11/site-packages/tensorflow/python/util/dispatch.py:1260\u001B[0m, in \u001B[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m   1258\u001B[0m \u001B[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001B[39;00m\n\u001B[1;32m   1259\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1260\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mdispatch_target\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1261\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (\u001B[38;5;167;01mTypeError\u001B[39;00m, \u001B[38;5;167;01mValueError\u001B[39;00m):\n\u001B[1;32m   1262\u001B[0m   \u001B[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001B[39;00m\n\u001B[1;32m   1263\u001B[0m   \u001B[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001B[39;00m\n\u001B[1;32m   1264\u001B[0m   result \u001B[38;5;241m=\u001B[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/rl-atari-7yjpj432/lib/python3.11/site-packages/tensorflow/python/ops/array_ops.py:4971\u001B[0m, in \u001B[0;36mgather_v2\u001B[0;34m(params, indices, validate_indices, axis, batch_dims, name)\u001B[0m\n\u001B[1;32m   4963\u001B[0m \u001B[38;5;129m@tf_export\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgather\u001B[39m\u001B[38;5;124m\"\u001B[39m, v1\u001B[38;5;241m=\u001B[39m[])\n\u001B[1;32m   4964\u001B[0m \u001B[38;5;129m@dispatch\u001B[39m\u001B[38;5;241m.\u001B[39madd_dispatch_support\n\u001B[1;32m   4965\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mgather_v2\u001B[39m(params,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   4969\u001B[0m               batch_dims\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m,\n\u001B[1;32m   4970\u001B[0m               name\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m-> 4971\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mgather\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   4972\u001B[0m \u001B[43m      \u001B[49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4973\u001B[0m \u001B[43m      \u001B[49m\u001B[43mindices\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4974\u001B[0m \u001B[43m      \u001B[49m\u001B[43mvalidate_indices\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalidate_indices\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4975\u001B[0m \u001B[43m      \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4976\u001B[0m \u001B[43m      \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4977\u001B[0m \u001B[43m      \u001B[49m\u001B[43mbatch_dims\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_dims\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/rl-atari-7yjpj432/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/rl-atari-7yjpj432/lib/python3.11/site-packages/tensorflow/python/util/dispatch.py:1260\u001B[0m, in \u001B[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m   1258\u001B[0m \u001B[38;5;66;03m# Fallback dispatch system (dispatch v1):\u001B[39;00m\n\u001B[1;32m   1259\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1260\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mdispatch_target\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1261\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (\u001B[38;5;167;01mTypeError\u001B[39;00m, \u001B[38;5;167;01mValueError\u001B[39;00m):\n\u001B[1;32m   1262\u001B[0m   \u001B[38;5;66;03m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001B[39;00m\n\u001B[1;32m   1263\u001B[0m   \u001B[38;5;66;03m# TypeError, when given unexpected types.  So we need to catch both.\u001B[39;00m\n\u001B[1;32m   1264\u001B[0m   result \u001B[38;5;241m=\u001B[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/rl-atari-7yjpj432/lib/python3.11/site-packages/tensorflow/python/util/deprecation.py:588\u001B[0m, in \u001B[0;36mdeprecated_args.<locals>.deprecated_wrapper.<locals>.new_func\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    580\u001B[0m         _PRINTED_WARNING[(func, arg_name)] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m    581\u001B[0m       _log_deprecation(\n\u001B[1;32m    582\u001B[0m           \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mFrom \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m: calling \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m (from \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m) with \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m is deprecated and will \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m    583\u001B[0m           \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbe removed \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mInstructions for updating:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    586\u001B[0m           \u001B[38;5;124m'\u001B[39m\u001B[38;5;124min a future version\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m date \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01melse\u001B[39;00m (\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mafter \u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m%\u001B[39m date),\n\u001B[1;32m    587\u001B[0m           instructions)\n\u001B[0;32m--> 588\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/rl-atari-7yjpj432/lib/python3.11/site-packages/tensorflow/python/ops/array_ops.py:4960\u001B[0m, in \u001B[0;36mgather\u001B[0;34m(***failed resolving arguments***)\u001B[0m\n\u001B[1;32m   4958\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m params\u001B[38;5;241m.\u001B[39msparse_read(indices, name\u001B[38;5;241m=\u001B[39mname)\n\u001B[1;32m   4959\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m:\n\u001B[0;32m-> 4960\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mgen_array_ops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgather_v2\u001B[49m\u001B[43m(\u001B[49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindices\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/rl-atari-7yjpj432/lib/python3.11/site-packages/tensorflow/python/ops/gen_array_ops.py:4068\u001B[0m, in \u001B[0;36mgather_v2\u001B[0;34m(params, indices, axis, batch_dims, name)\u001B[0m\n\u001B[1;32m   4066\u001B[0m   batch_dims \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m   4067\u001B[0m batch_dims \u001B[38;5;241m=\u001B[39m _execute\u001B[38;5;241m.\u001B[39mmake_int(batch_dims, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mbatch_dims\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m-> 4068\u001B[0m _, _, _op, _outputs \u001B[38;5;241m=\u001B[39m \u001B[43m_op_def_library\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_apply_op_helper\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   4069\u001B[0m \u001B[43m      \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mGatherV2\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparams\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindices\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mindices\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maxis\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   4070\u001B[0m \u001B[43m                  \u001B[49m\u001B[43mbatch_dims\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_dims\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   4071\u001B[0m _result \u001B[38;5;241m=\u001B[39m _outputs[:]\n\u001B[1;32m   4072\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m _execute\u001B[38;5;241m.\u001B[39mmust_record_gradient():\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/rl-atari-7yjpj432/lib/python3.11/site-packages/tensorflow/python/framework/op_def_library.py:776\u001B[0m, in \u001B[0;36m_apply_op_helper\u001B[0;34m(op_type_name, name, **keywords)\u001B[0m\n\u001B[1;32m    771\u001B[0m   _ExtractDefaultTypesAndAllowedTypes(op_def, default_type_attr_map,\n\u001B[1;32m    772\u001B[0m                                       allowed_list_attr_map)\n\u001B[1;32m    774\u001B[0m \u001B[38;5;66;03m# Requires that op_def has passed validation (using the C++\u001B[39;00m\n\u001B[1;32m    775\u001B[0m \u001B[38;5;66;03m# ValidateOpDef() from ../framework/op_def_util.h).\u001B[39;00m\n\u001B[0;32m--> 776\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[43mg\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mas_default\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m, ops\u001B[38;5;241m.\u001B[39mname_scope(name) \u001B[38;5;28;01mas\u001B[39;00m scope:\n\u001B[1;32m    777\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m fallback:\n\u001B[1;32m    778\u001B[0m     _ExtractInputsAndAttrs(op_type_name, op_def, allowed_list_attr_map,\n\u001B[1;32m    779\u001B[0m                            keywords, default_type_attr_map, attrs, inputs,\n\u001B[1;32m    780\u001B[0m                            input_types)\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/rl-atari-7yjpj432/lib/python3.11/site-packages/tensorflow/python/framework/func_graph.py:445\u001B[0m, in \u001B[0;36mFuncGraph.as_default\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    442\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mas_default\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    443\u001B[0m   outer_cm \u001B[38;5;241m=\u001B[39m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39mas_default()\n\u001B[0;32m--> 445\u001B[0m \u001B[43m  \u001B[49m\u001B[38;5;129;43m@tf_contextlib\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcontextmanager\u001B[49m\n\u001B[1;32m    446\u001B[0m \u001B[43m  \u001B[49m\u001B[38;5;28;43;01mdef\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;21;43minner_cm\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\n\u001B[1;32m    447\u001B[0m \u001B[38;5;250;43m    \u001B[39;49m\u001B[38;5;124;43;03m\"\"\"Context manager for copying distribute.Strategy scope information.\"\"\"\u001B[39;49;00m\n\u001B[1;32m    448\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# pylint: disable=protected-access\u001B[39;49;00m\n\u001B[1;32m    449\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# TODO(b/112906995, nareshmodi): distribution strategy depends on\u001B[39;49;00m\n\u001B[1;32m    450\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# inheriting this stack from the default graph even in eager mode. Maybe\u001B[39;49;00m\n\u001B[1;32m    451\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# it should be part of the eager context? This would also allow us to\u001B[39;49;00m\n\u001B[1;32m    452\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m# remove a get_default_graph() call from the function cache lookup.\u001B[39;49;00m\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/rl-atari-7yjpj432/lib/python3.11/site-packages/tensorflow/python/util/tf_contextlib.py:39\u001B[0m, in \u001B[0;36mcontextmanager\u001B[0;34m(target)\u001B[0m\n\u001B[1;32m     29\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"A tf_decorator-aware wrapper for `contextlib.contextmanager`.\u001B[39;00m\n\u001B[1;32m     30\u001B[0m \n\u001B[1;32m     31\u001B[0m \u001B[38;5;124;03mUsage is identical to `contextlib.contextmanager`.\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     36\u001B[0m \u001B[38;5;124;03m  A callable that can be used inside of a `with` statement.\u001B[39;00m\n\u001B[1;32m     37\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     38\u001B[0m context_manager \u001B[38;5;241m=\u001B[39m _contextlib\u001B[38;5;241m.\u001B[39mcontextmanager(target)\n\u001B[0;32m---> 39\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtf_decorator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmake_decorator\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcontext_manager\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mcontextmanager\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/rl-atari-7yjpj432/lib/python3.11/site-packages/tensorflow/python/util/tf_decorator.py:136\u001B[0m, in \u001B[0;36mmake_decorator\u001B[0;34m(target, decorator_func, decorator_name, decorator_doc, decorator_argspec)\u001B[0m\n\u001B[1;32m    134\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m decorator_name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    135\u001B[0m   decorator_name \u001B[38;5;241m=\u001B[39m inspect\u001B[38;5;241m.\u001B[39mcurrentframe()\u001B[38;5;241m.\u001B[39mf_back\u001B[38;5;241m.\u001B[39mf_code\u001B[38;5;241m.\u001B[39mco_name\n\u001B[0;32m--> 136\u001B[0m decorator \u001B[38;5;241m=\u001B[39m \u001B[43mTFDecorator\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdecorator_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdecorator_doc\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    137\u001B[0m \u001B[43m                        \u001B[49m\u001B[43mdecorator_argspec\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    138\u001B[0m \u001B[38;5;28msetattr\u001B[39m(decorator_func, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m_tf_decorator\u001B[39m\u001B[38;5;124m'\u001B[39m, decorator)\n\u001B[1;32m    139\u001B[0m \u001B[38;5;66;03m# Objects that are callables (e.g., a functools.partial object) may not have\u001B[39;00m\n\u001B[1;32m    140\u001B[0m \u001B[38;5;66;03m# the following attributes.\u001B[39;00m\n",
      "File \u001B[0;32m~/.local/share/virtualenvs/rl-atari-7yjpj432/lib/python3.11/site-packages/tensorflow/python/util/tf_decorator.py:332\u001B[0m, in \u001B[0;36mTFDecorator.__init__\u001B[0;34m(self, decorator_name, target, decorator_doc, decorator_argspec)\u001B[0m\n\u001B[1;32m    330\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mcallable\u001B[39m(target):\n\u001B[1;32m    331\u001B[0m   \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 332\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m__signature__ \u001B[38;5;241m=\u001B[39m \u001B[43minspect\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msignature\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    333\u001B[0m   \u001B[38;5;28;01mexcept\u001B[39;00m (\u001B[38;5;167;01mTypeError\u001B[39;00m, \u001B[38;5;167;01mValueError\u001B[39;00m):\n\u001B[1;32m    334\u001B[0m     \u001B[38;5;66;03m# Certain callables such as builtins can not be inspected for signature.\u001B[39;00m\n\u001B[1;32m    335\u001B[0m     \u001B[38;5;28;01mpass\u001B[39;00m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/inspect.py:3280\u001B[0m, in \u001B[0;36msignature\u001B[0;34m(obj, follow_wrapped, globals, locals, eval_str)\u001B[0m\n\u001B[1;32m   3278\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21msignature\u001B[39m(obj, \u001B[38;5;241m*\u001B[39m, follow_wrapped\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, \u001B[38;5;28mglobals\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;28mlocals\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, eval_str\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[1;32m   3279\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Get a signature object for the passed callable.\"\"\"\u001B[39;00m\n\u001B[0;32m-> 3280\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mSignature\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfrom_callable\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobj\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfollow_wrapped\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfollow_wrapped\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3281\u001B[0m \u001B[43m                                   \u001B[49m\u001B[38;5;28;43mglobals\u001B[39;49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mglobals\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mlocals\u001B[39;49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mlocals\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43meval_str\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43meval_str\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/inspect.py:3028\u001B[0m, in \u001B[0;36mSignature.from_callable\u001B[0;34m(cls, obj, follow_wrapped, globals, locals, eval_str)\u001B[0m\n\u001B[1;32m   3024\u001B[0m \u001B[38;5;129m@classmethod\u001B[39m\n\u001B[1;32m   3025\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfrom_callable\u001B[39m(\u001B[38;5;28mcls\u001B[39m, obj, \u001B[38;5;241m*\u001B[39m,\n\u001B[1;32m   3026\u001B[0m                   follow_wrapped\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, \u001B[38;5;28mglobals\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;28mlocals\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, eval_str\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[1;32m   3027\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Constructs Signature for the given callable object.\"\"\"\u001B[39;00m\n\u001B[0;32m-> 3028\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_signature_from_callable\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobj\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msigcls\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mcls\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3029\u001B[0m \u001B[43m                                    \u001B[49m\u001B[43mfollow_wrapper_chains\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfollow_wrapped\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   3030\u001B[0m \u001B[43m                                    \u001B[49m\u001B[38;5;28;43mglobals\u001B[39;49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mglobals\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mlocals\u001B[39;49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mlocals\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43meval_str\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43meval_str\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/inspect.py:2513\u001B[0m, in \u001B[0;36m_signature_from_callable\u001B[0;34m(obj, follow_wrapper_chains, skip_bound_arg, globals, locals, eval_str, sigcls)\u001B[0m\n\u001B[1;32m   2510\u001B[0m             new_params \u001B[38;5;241m=\u001B[39m (first_wrapped_param,) \u001B[38;5;241m+\u001B[39m sig_params\n\u001B[1;32m   2511\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m sig\u001B[38;5;241m.\u001B[39mreplace(parameters\u001B[38;5;241m=\u001B[39mnew_params)\n\u001B[0;32m-> 2513\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[43misfunction\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobj\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;129;01mor\u001B[39;00m _signature_is_functionlike(obj):\n\u001B[1;32m   2514\u001B[0m     \u001B[38;5;66;03m# If it's a pure Python function, or an object that is duck type\u001B[39;00m\n\u001B[1;32m   2515\u001B[0m     \u001B[38;5;66;03m# of a Python function (Cython functions, for instance), then:\u001B[39;00m\n\u001B[1;32m   2516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m _signature_from_function(sigcls, obj,\n\u001B[1;32m   2517\u001B[0m                                     skip_bound_arg\u001B[38;5;241m=\u001B[39mskip_bound_arg,\n\u001B[1;32m   2518\u001B[0m                                     \u001B[38;5;28mglobals\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mglobals\u001B[39m, \u001B[38;5;28mlocals\u001B[39m\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mlocals\u001B[39m, eval_str\u001B[38;5;241m=\u001B[39meval_str)\n\u001B[1;32m   2520\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m _signature_is_builtin(obj):\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/inspect.py:378\u001B[0m, in \u001B[0;36misfunction\u001B[0;34m(object)\u001B[0m\n\u001B[1;32m    372\u001B[0m \u001B[38;5;250m        \u001B[39m\u001B[38;5;124;03m\"\"\"Return true if the object is a getset descriptor.\u001B[39;00m\n\u001B[1;32m    373\u001B[0m \n\u001B[1;32m    374\u001B[0m \u001B[38;5;124;03m        getset descriptors are specialized descriptors defined in extension\u001B[39;00m\n\u001B[1;32m    375\u001B[0m \u001B[38;5;124;03m        modules.\"\"\"\u001B[39;00m\n\u001B[1;32m    376\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m--> 378\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21misfunction\u001B[39m(\u001B[38;5;28mobject\u001B[39m):\n\u001B[1;32m    379\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Return true if the object is a user-defined function.\u001B[39;00m\n\u001B[1;32m    380\u001B[0m \n\u001B[1;32m    381\u001B[0m \u001B[38;5;124;03m    Function objects provide these attributes:\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    387\u001B[0m \u001B[38;5;124;03m        __annotations__ dict of parameter annotations\u001B[39;00m\n\u001B[1;32m    388\u001B[0m \u001B[38;5;124;03m        __kwdefaults__  dict of keyword only parameters with defaults\"\"\"\u001B[39;00m\n\u001B[1;32m    389\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(\u001B[38;5;28mobject\u001B[39m, types\u001B[38;5;241m.\u001B[39mFunctionType)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "qbert_rewards, qbert_max_steps, qbert_q_values, qbert_losses, qbert_model = train_dqn(\"ALE/Qbert-v5\", method=\"dqn\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-25T20:45:09.441175Z",
     "start_time": "2024-04-25T20:42:51.061599Z"
    }
   },
   "id": "4987271d8425f719",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "plot_rewards(qbert_rewards, title='Qbert Rewards Over Episodes')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7002b126ba1499b",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "plot_q(qbert_q_values, title='Qbert Q Values Over Episodes')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "56377475b564c884",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "np.save(\"../data/save/qbert_rewards_dqn.npy\", np.array(qbert_rewards))\n",
    "np.save(\"../data/save/qbert_max_steps_dqn.npy\", np.array(qbert_max_steps))\n",
    "np.save(\"../data/save/qbert_q_values_dqn.npy\", np.array(qbert_q_values))\n",
    "np.save(\"../data/save/qbert_losses_dqn.npy\", np.array(qbert_losses))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a9e5e9c9e99ae2ed",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "qbert_model.save(\"../data/saved_models/qbert_model_dqn.keras\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5cc174ee10ea06db",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "6f9d4edb1d142639"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
